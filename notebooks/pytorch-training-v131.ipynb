{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/usr/net/zinovyee.hub/Datathons/cassava/notebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0V4vZ6Qm0ViG"
   },
   "source": [
    "# PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZGLrkTFa0ViK"
   },
   "outputs": [],
   "source": [
    "####### CONFIGURATION\n",
    "\n",
    "class CFG:\n",
    "\n",
    "    # environment\n",
    "    environment = 'local'  # work environment ('kaggle', 'colab', 'local')\n",
    "    device      = 'GPU'    # device ('CPU', 'GPU', 'TPU')\n",
    "    num_workers = 4        # no. cores\n",
    "\n",
    "    # general\n",
    "    version  = 131   # notebook version (for saving outputs)\n",
    "    debug    = False  # debug mode runs 5 batches for 2 epochs \n",
    "    training = True  # if False, only inference is run\n",
    "    tracking = True # track results using neptune.ai\n",
    "    seed     = 13353 # random state\n",
    "\n",
    "    # data\n",
    "    num_folds  = 5      # number of CV folds\n",
    "    data_2019  = True   # append 2019 labeled data to training folds (1a)\n",
    "    data_pl    = 0.2    # False or percentage of appended pseudo-labeled data (1b)\n",
    "    data_ext   = False  # False or list with external dataset ids (2, 3, 4, 5)\n",
    "    drop_dupl  = True   # drop duplicate images from training folds\n",
    "    drop_outs  = False  # drop outliers from training folds\n",
    "    oversample = False  # enable oversampling through WeightedRandomSampler()\n",
    "    \n",
    "    # label noise\n",
    "    drop_noise = False  # False or percentage of removed noisy labels in training folds\n",
    "    flip_noise  = False  # False or percentage of flipped noisy labels in training folds\n",
    "\n",
    "    # image size and augmentations \n",
    "    image_size   = 384               # image size after random crop\n",
    "    crop_scale   = (0.10, 1)          # min scale, max scale\n",
    "    gr_shuffle     = (3, 3)             # number of tiles in shuffled grid\n",
    "    ssr          = [0.05, 0.05, 360]  # shift, scale, rotation limits\n",
    "    huesat       = [20, 20, 20]       # hue, saturation, value limits\n",
    "    bricon       = [0.1, 0.1]         # brightness, contrast limits\n",
    "    blur_limit   = 3                  # blur limit\n",
    "    dist_limit   = 0.1                # distortion limit\n",
    "    cutout       = [5, 0.1]           # number of squares, size of squares\n",
    "    p_augment    = 0.5                # prob. of augmentations except for flips\n",
    "    cutmix       = [0, 1]             # cutmix batch-level probability, alpha\n",
    "    normalize    = False              # pixel normalization (False, 'dataset', 'imagenet')\n",
    "    pairing      = False              # overlay of a random image from the same class\n",
    "    pairing_prob = 0.6                # probability of an image to get another image added\n",
    "    pixel_crop   = 150                # hight and width of the crop\n",
    "\n",
    "    # model architecture\n",
    "    backbone = 'vit_base_patch16_384' # convolutional backbone\n",
    "    weights  = 'imagenet'              # weights ('empty', 'imagenet', 'custom')\n",
    "    save_all = False                   # save weights from each epoch\n",
    "\n",
    "    # pretrained model\n",
    "    pr_version     = 3   # notebook version (2, 3, 4, 5)\n",
    "    pr_num_classes = 10  # no. classes (2: 4, 3: 10, 4: 2, 5: 17)\n",
    "\n",
    "    # training\n",
    "    batch_size  = 16    # no. images per batch\n",
    "    num_epochs  = 10    # no. epochs per fold\n",
    "    fine_tune    = 2     # fine-tuning dense layers (False or no. epochs)\n",
    "    accum_iter  = 2     # no. batches for gradient accumalation\n",
    "    use_amp     = True  # automated mixed precision mode\n",
    "\n",
    "    # learning rate and optimizer\n",
    "    eta     = 1e-4    # starting learning rate\n",
    "    eta_min = 1e-6    # ending learning rate\n",
    "    optim   = 'AdamP' # LR optimizer ('Adam', 'AdamW', 'AdamP')\n",
    "    decay   = 0       # weight decay of optimizer (L2 regularization)\n",
    "\n",
    "    # learning rate scheduler\n",
    "    warmup          = 1                  # no. epochs for warmup\n",
    "    schedule        = 'CosineAnnealing'  # LR scheduler after warmup\n",
    "    update_on_batch = True               # update LR after every batch or epoch\n",
    "\n",
    "    # loss function\n",
    "    loss_fn     = 'OHEM'         # loss function ('CE', 'OHEM', 'SCE', 'CCE', 'Focal', 'FocalCosine', 'Taylor', 'BiTempered')\n",
    "    smoothing   = 0.2          # label smoothing (works with all losses)\n",
    "    ohem        = 0.8          # OHEM loss parameters: top-k percentage\n",
    "    sce         = [0.1, 1.0]   # SCE loss parameters: alpha, beta\n",
    "    cce         = 5            # CCE loss parameters: gamma\n",
    "    focal       = [1, 2]       # Focal loss parameters: alpha, gamma\n",
    "    focalcosine = [1, 2, 0.1]  # FocalCosine loss parameters: alpha, gamma, xent\n",
    "    taylor      = 2            # Taylor loss parameters: n\n",
    "    bitempered  = [0.3, 1.0]   # BiTempered loss parameters: t1, t2\n",
    "\n",
    "    # epoch-based changes\n",
    "    step_size  = False  # False or list with image_size multiplier for each epoch\n",
    "    step_class = False  # False or list with num_classes for each epoch (2 or 5)\n",
    "    step_p_aug = False  # False or list with p_augment multiplier for each epoch\n",
    "    step_loss  = False  # False or list with loss functions for each epoch\n",
    "\n",
    "    # inference\n",
    "    num_tta = 1  # no. TTA flips (between 1 and 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ONx3m0TJ2PJ1"
   },
   "outputs": [],
   "source": [
    "####### CONVERT CONFIGURATION\n",
    "\n",
    "CFG = dict(vars(CFG))\n",
    "for key in ['__dict__', '__doc__', '__module__', '__weakref__']:\n",
    "    del CFG[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9ZKt08y0ViT"
   },
   "source": [
    "# PREPARATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nAfc6niM0ep4",
    "outputId": "0397bcd7-7ff4-4809-be9d-f81170eaf814"
   },
   "outputs": [],
   "source": [
    "####### ENVIRONMENT SETUP\n",
    "\n",
    "##### COLAB\n",
    "\n",
    "import os\n",
    "if (CFG['environment'] == 'colab') and (not os.path.exists('/content/cassava/')):\n",
    "\n",
    "    # mount drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')  \n",
    "\n",
    "    # set up Kaggle API\n",
    "    !pip install --upgrade --force-reinstall --no-deps -q kaggle\n",
    "    !mkdir -p ~/.kaggle\n",
    "    !cp '/content/drive/MyDrive/Competitions/kaggle.json' ~/.kaggle/\n",
    "    !ls ~/.kaggle\n",
    "\n",
    "    # download data\n",
    "    !mkdir '/content/cassava/'\n",
    "    !kaggle kernels output kozodoi/merge-and-zip-2019-2020-data -p '/content/cassava/'\n",
    "    !unzip -o -q '/content/cassava/images.zip' -d '/content/cassava/'\n",
    "    !rm -rf '/content/cassava/images.zip'\n",
    "    \n",
    "    \n",
    "##### KAGGLE\n",
    "\n",
    "if (CFG['environment'] == 'kaggle') and (not os.path.exists('cassava/')):\n",
    "\n",
    "    # extract data\n",
    "    !mkdir 'cassava/'\n",
    "    !unzip -o -q '/kaggle/input/merge-and-zip-2019-2020-data/images.zip' -d 'cassava/'\n",
    "    !cp '/kaggle/input/merge-and-zip-2019-2020-data/train.csv' 'cassava/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_X93RyNgsJI"
   },
   "outputs": [],
   "source": [
    "####### WORKING PATHS\n",
    "\n",
    "# kaggle\n",
    "if CFG['environment'] == 'kaggle':\n",
    "    CFG['data_path']  = 'cassava/'\n",
    "    CFG['model_path'] = ''\n",
    "    CFG['out_path']   = ''\n",
    "\n",
    "# colab\n",
    "if CFG['environment'] == 'colab':\n",
    "    CFG['data_path']  = '/content/cassava/'\n",
    "    CFG['model_path'] = '/content/drive/MyDrive/Cassava/pretraining/v' + str(CFG['pr_version']) + '/'\n",
    "    CFG['out_path']   = '/content/drive/MyDrive/Cassava/training/v'    + str(CFG['version'])    + '/'\n",
    "    if not os.path.exists(CFG['out_path']):\n",
    "        os.mkdir(CFG['out_path'])\n",
    "\n",
    "# local\n",
    "if CFG['environment'] == 'local':\n",
    "    CFG['data_path']  = '../data/'\n",
    "    CFG['model_path'] = '../pretraining/v' + str(CFG['pr_version']) + '/'\n",
    "    CFG['out_path']   = '../training/v'    + str(CFG['version'])    + '/'\n",
    "    if not os.path.exists(CFG['out_path']):\n",
    "        os.mkdir(CFG['out_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HIjTLhkSBRbe"
   },
   "outputs": [],
   "source": [
    "####### PACKAGES FOR TPU\n",
    "\n",
    "if CFG['device'] == 'TPU':\n",
    "        \n",
    "    # install XLA\n",
    "    xla_version = 'nightly' # (1.7, 'nightly')\n",
    "    !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "    !python pytorch-xla-env-setup.py --version $xla_version\n",
    "\n",
    "    # settings\n",
    "    if CFG['environment'] == 'colab':\n",
    "        import os\n",
    "        assert os.environ['COLAB_TPU_ADDR']\n",
    "    os.environ['XLA_USE_BF_16'] = '1'\n",
    "    os.environ['XLA_TENSOR_ALLOCATOR_MAXSIZE'] = '100000000'\n",
    "\n",
    "    # imports\n",
    "    import torch_xla\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "    import torch_xla.distributed.parallel_loader as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S6rE_WKH0ViV",
    "outputId": "f89011cf-9e06-4ee5-9705-ac153535284a"
   },
   "outputs": [],
   "source": [
    "####### PACKAGES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler, WeightedRandomSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "from torch.autograd import Function\n",
    "\n",
    "!pip install timm\n",
    "import timm\n",
    "from timm.utils import *\n",
    "\n",
    "from contextlib import suppress\n",
    "\n",
    "!pip install --upgrade -U albumentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "!pip install git+'https://github.com/ildoonet/pytorch-gradual-warmup-lr.git'\n",
    "from warmup_scheduler import GradualWarmupScheduler  \n",
    "\n",
    "!pip install adamp\n",
    "from adamp import AdamP\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import cv2\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from scipy.special import softmax\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNePNOxvCCkS"
   },
   "outputs": [],
   "source": [
    "####### TRACKING WITH NEPTUNE\n",
    "\n",
    "if CFG['tracking']:\n",
    "    \n",
    "    # install neptune\n",
    "    !pip install neptune-client\n",
    "    import neptune \n",
    "\n",
    "    # create exoeriment\n",
    "    neptune.init(api_token = 'eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5haSIsImFwaV91cmwiOiJodHRwczovL3VpLm5lcHR1bmUuYWkiLCJhcGlfa2V5IjoiZjQ1ZTgwOTYtZjcwNy00MjkyLTg0ZTQtZDBmMzk5MGNjOTE1In0=',\n",
    "                 project_qualified_name = 'kozodoi/cassava')\n",
    "    neptune.create_experiment(name = 'v' + str(CFG['version']), params = CFG) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jwoqOvA10Vim",
    "outputId": "dfa9e699-b233-49ee-b195-6021d0ba1eb4"
   },
   "outputs": [],
   "source": [
    "####### TRAINING DEVICE\n",
    "\n",
    "if CFG['device'] == 'TPU':\n",
    "    print('Training on TPU...')\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "if CFG['device'] == 'GPU':\n",
    "    print('Training on GPU...')\n",
    "    if CFG['environment'] == 'local':\n",
    "        device = torch.device('cuda:1')\n",
    "    else:\n",
    "        device = torch.device('cuda:0')\n",
    "\n",
    "if CFG['device'] == 'CPU':\n",
    "    print('Training on CPU...')\n",
    "    device = torch.device('cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FFu8LLDkfRnz",
    "outputId": "60efbef8-b055-4827-8028-dfbf9722601d"
   },
   "outputs": [],
   "source": [
    "####### UTILITIES\n",
    "\n",
    "##### RANDOM FOR LOOPS\n",
    "\n",
    "def randomly(seq):\n",
    "    shuffled = list(seq)\n",
    "    random.shuffle(shuffled)\n",
    "    return iter(shuffled)\n",
    "\n",
    "\n",
    "##### DEVICE-AWARE PRINTING \n",
    "\n",
    "def smart_print(expression, CFG):\n",
    "    if CFG['device'] != 'TPU':\n",
    "        print(expression)\n",
    "    else:\n",
    "        xm.master_print(expression)\n",
    "\n",
    "\n",
    "##### DEVICE-AWARE SAVING\n",
    "\n",
    "def smart_save(weights, path, CFG):\n",
    "    if CFG['device'] != 'TPU':\n",
    "        torch.save(weights, path)    \n",
    "    else:\n",
    "        xm.save(weights, path) \n",
    "\n",
    "    \n",
    "##### RANDOMNESS\n",
    "\n",
    "def seed_everything(seed, CFG):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    smart_print('Setting random seed to {}...'.format(seed), CFG)\n",
    "    \n",
    "seed_everything(CFG['seed'], CFG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2OuAGJw0Viv"
   },
   "source": [
    "# DATA PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "70WIWDTE0Vi8",
    "outputId": "2cad2e1a-70d4-45d1-d35b-b3748575df8d"
   },
   "outputs": [],
   "source": [
    "####### 2020 COMPETITION DATA\n",
    "\n",
    "# import data\n",
    "df = pd.read_csv(CFG['data_path'] + 'train.csv')\n",
    "df = df.loc[df['source'] == 2020].reset_index(drop = True)\n",
    "    \n",
    "# num classes\n",
    "CFG['num_classes'] = df['label'].nunique()\n",
    "\n",
    "# partitioning\n",
    "df['fold'] = -1\n",
    "skf = StratifiedKFold(n_splits = CFG['num_folds'], random_state = CFG['seed'], shuffle = True)\n",
    "for fold, (trn_idx, val_idx) in enumerate(skf.split(df, df['label'])):\n",
    "    df.loc[val_idx, 'fold'] = fold\n",
    "    \n",
    "# check folds\n",
    "pd.crosstab(df['fold'], df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "0m1cX4ACuBxn",
    "outputId": "0e3e56bf-33e5-4322-9c78-cd506d762419"
   },
   "outputs": [],
   "source": [
    "####### 2019 COMPETITION DATA\n",
    "\n",
    "##### LABELED DATA\n",
    "\n",
    "if CFG['data_2019']:\n",
    "\n",
    "    # import data\n",
    "    df_2019 = pd.read_csv(CFG['data_path'] + 'train.csv')\n",
    "    df_2019 = df_2019.loc[df_2019['source'] == 2019].reset_index(drop = True)\n",
    "    df_2019['fold'] = -1\n",
    "        \n",
    "    # check classes\n",
    "    display(df_2019['label'].value_counts())\n",
    "\n",
    "\n",
    "##### PSEUDO-LABELED DATA\n",
    "\n",
    "if CFG['data_pl']:\n",
    "\n",
    "    # import\n",
    "    if CFG['environment'] == 'colab':\n",
    "        !kaggle kernels output kozodoi/pseudo-labeling-v57 -p '/content/cassava/'\n",
    "        !unzip -o -q '/content/cassava/unlabeled_images.zip' -d '/content/cassava/train_images/'\n",
    "        !rm -rf '/content/cassava/unlabeled_images.zip'\n",
    "    df_pl = pd.read_csv(CFG['data_path'] + 'df_pl.csv')\n",
    "    df_pl['fold'] = -1\n",
    "\n",
    "    # filter confident predictions\n",
    "    df_pl['confidence'] = df_pl.filter(like = 'c').max(axis = 1)\n",
    "    df_pl = df_pl.sort_values('confidence', ascending = False)\n",
    "    df_pl = df_pl.head(int(CFG['data_pl'] * len(df_pl)))\n",
    "    df_pl = df_pl[['image_id', 'label', 'fold']]\n",
    "\n",
    "    # check classes\n",
    "    display(df_pl['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kvG_0mWICb-U"
   },
   "outputs": [],
   "source": [
    "####### EXTERNAL DATA [HEALTHY]\n",
    "\n",
    "if CFG['data_ext']:\n",
    "\n",
    "    # placeholder\n",
    "    df_ext = pd.DataFrame(columns = ['image_id', 'label', 'source'])\n",
    "\n",
    "\n",
    "    ##### DATASET 2\n",
    "\n",
    "    if 2 in CFG['data_ext']:\n",
    "\n",
    "        # import images\n",
    "        !kaggle kernels output kozodoi/prepare-dataset-2 -p '/content/cassava/'\n",
    "        !unzip -o -q '/content/cassava/images.zip' -d '/content/cassava/train_images/'\n",
    "        !rm -rf '/content/cassava/images.zip'\n",
    "\n",
    "        # filtering\n",
    "        df_2 = pd.read_csv(CFG['data_path'] + 'df_2.csv')\n",
    "        df_2 = df_2.loc[df_2['label'] == 4].reset_index(drop = True)\n",
    "        df_2['source'] = 2\n",
    "        df_ext = pd.concat([df_ext, df_2], axis = 0).reset_index(drop = True)\n",
    "        \n",
    "\n",
    "    ##### DATASET 3\n",
    "\n",
    "    if 3 in CFG['data_ext']:\n",
    "\n",
    "        # import\n",
    "        !kaggle kernels output kozodoi/prepare-dataset-3 -p '/content/cassava/'\n",
    "        !unzip -o -q '/content/cassava/images.zip' -d '/content/cassava/train_images/'\n",
    "        !rm -rf '/content/cassava/images.zip'\n",
    "\n",
    "        # filtering\n",
    "        df_3 = pd.read_csv(CFG['data_path'] + 'df_3.csv')\n",
    "        df_3 = df_3.loc[df_3['label'] == 4].reset_index(drop = True)\n",
    "        df_3['source'] = 3\n",
    "        df_ext = pd.concat([df_ext, df_3], axis = 0).reset_index(drop = True)\n",
    "\n",
    "\n",
    "    ##### DATASET 4\n",
    "\n",
    "    if 4 in CFG['data_ext']:\n",
    "\n",
    "        # import\n",
    "        !kaggle kernels output kozodoi/prepare-dataset-4 -p '/content/cassava/'\n",
    "        !unzip -o -q '/content/cassava/images.zip' -d '/content/cassava/train_images/'\n",
    "        !rm -rf '/content/cassava/images.zip'\n",
    "\n",
    "        # filtering\n",
    "        df_4 = pd.read_csv(CFG['data_path'] + 'df_4.csv')\n",
    "        df_4 = df_4.loc[df_4['label'] == 4].reset_index(drop = True)\n",
    "        df_4['source'] = 4\n",
    "        df_ext = pd.concat([df_ext, df_4], axis = 0).reset_index(drop = True)\n",
    "\n",
    "\n",
    "    ##### DATASET 5\n",
    "\n",
    "    if 5 in CFG['data_ext']:\n",
    "\n",
    "        # import\n",
    "        !kaggle kernels output kozodoi/prepare-dataset-5 -p '/content/cassava/'\n",
    "        !unzip -o -q '/content/cassava/images.zip' -d '/content/cassava/train_images/'\n",
    "        !rm -rf '/content/cassava/images.zip'\n",
    "\n",
    "        # filtering\n",
    "        df_5 = pd.read_csv(CFG['data_path'] + 'df_5.csv')\n",
    "        df_5 = df_5.loc[df_5['label'] == 4].reset_index(drop = True)\n",
    "        df_5['source'] = 5\n",
    "        df_ext = pd.concat([df_ext, df_5], axis = 0).reset_index(drop = True)\n",
    "\n",
    "\n",
    "    ##### PARTITIONING\n",
    "\n",
    "    df_ext['source'] = df_ext['source'].astype('int')\n",
    "    df_ext['fold']   = -1\n",
    "    display(df_ext['source'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bo5lww9Jpim1",
    "outputId": "26c2936f-e6ec-4331-db74-7506e2a51b1f"
   },
   "outputs": [],
   "source": [
    "####### IDENTIFY BAD EXAMPLES\n",
    "\n",
    "##### DUPLICATES\n",
    "\n",
    "if CFG['drop_dupl']:\n",
    "\n",
    "    # duplicates: 2019 vs 2020 (hash)\n",
    "    #duplicates = [('1002088496.jpg', 'train-cbsd-614.jpg'), ('1024367055.jpg', 'train-cgm-677.jpg'), ('1046486747.jpg', 'train-cbsd-1272.jpg'), ('1050134400.jpg', 'train-cmd-1049.jpg'), ('1059986462.jpg', 'train-cgm-416.jpg'), ('1069816211.jpg', 'train-cgm-456.jpg'), ('1072259548.jpg', 'train-cbsd-355.jpg'), ('1080179563.jpg', 'train-cmd-10.jpg'), ('1080281713.jpg', 'train-cmd-1009.jpg'), ('1081937072.jpg', 'train-cmd-809.jpg'), ('1089661926.jpg', 'train-cbsd-1248.jpg'), ('1099882902.jpg', 'train-cbsd-50.jpg'), ('1102683272.jpg', 'train-cmd-2099.jpg'), ('1118493919.jpg', 'train-cmd-1643.jpg'), ('112557905.jpg', 'train-cmd-207.jpg'), ('1128747807.jpg', 'train-cmd-2601.jpg'), ('1133309905.jpg', 'train-cgm-714.jpg'), ('114251805.jpg', 'train-cgm-482.jpg'), ('1143548479.jpg', 'train-cmd-1456.jpg'), ('1144657211.jpg', 'train-cmd-646.jpg'), ('11690064.jpg', 'train-cbb-345.jpg'), ('1172621803.jpg', 'train-cmd-2371.jpg'), ('1180559828.jpg', 'train-cmd-986.jpg'), ('1194116552.jpg', 'train-cmd-2630.jpg'), ('1197262681.jpg', 'train-cmd-2222.jpg'), ('1199797130.jpg', 'train-cgm-303.jpg'), ('1209827516.jpg', 'train-cgm-438.jpg'), ('1215008377.jpg', 'train-cmd-42.jpg'), ('1227903119.jpg', 'train-cmd-528.jpg'), ('1234931385.jpg', 'train-cgm-515.jpg'), ('1239998285.jpg', 'train-cbsd-1213.jpg'), ('1242546458.jpg', 'train-cmd-411.jpg'), ('125037460.jpg', 'train-cmd-363.jpg'), ('1252538311.jpg', 'train-cmd-1558.jpg'), ('1261540961.jpg', 'train-cmd-1698.jpg'), ('1264219928.jpg', 'train-cgm-426.jpg'), ('1275608644.jpg', 'train-cmd-1278.jpg'), ('1276802461.jpg', 'train-cbb-261.jpg'), ('1277936443.jpg', 'train-cmd-1970.jpg'), ('1285287595.jpg', 'train-cbsd-293.jpg'), ('1285588852.jpg', 'train-cbsd-446.jpg'), ('128820265.jpg', 'train-cmd-2535.jpg'), ('1290734565.jpg', 'train-cmd-2507.jpg'), ('1302078468.jpg', 'train-cbsd-1203.jpg'), ('1303876802.jpg', 'train-cbb-429.jpg'), ('1324257289.jpg', 'train-cmd-2124.jpg'), ('1335452154.jpg', 'train-cmd-2260.jpg'), ('1335531094.jpg', 'train-cbsd-1390.jpg'), ('1339257499.jpg', 'train-cbb-18.jpg'), ('1348941923.jpg', 'train-cmd-1194.jpg'), ('1359438859.jpg', 'train-cbb-448.jpg'), ('1362645481.jpg', 'train-cmd-2602.jpg'), ('1368162685.jpg', 'train-cgm-213.jpg'), ('1381222280.jpg', 'train-cmd-2481.jpg'), ('1385160350.jpg', 'train-cmd-2316.jpg'), ('1386157120.jpg', 'train-cmd-1724.jpg'), ('1387354222.jpg', 'train-cmd-279.jpg'), ('13975743.jpg', 'train-cgm-291.jpg'), ('1415940915.jpg', 'train-cmd-1659.jpg'), ('1418463220.jpg', 'train-cgm-405.jpg'), ('1424930187.jpg', 'train-cmd-1454.jpg'), ('1432249645.jpg', 'train-cbsd-157.jpg'), ('1438970432.jpg', 'train-cmd-489.jpg'), ('1442451975.jpg', 'train-cmd-1806.jpg'), ('1443356256.jpg', 'train-cgm-109.jpg'), ('144873912.jpg', 'train-cmd-500.jpg'), ('1451862945.jpg', 'train-cmd-100.jpg'), ('1454074626.jpg', 'train-cmd-200.jpg'), ('1455906876.jpg', 'train-cbsd-1056.jpg'), ('145911417.jpg', 'train-cmd-625.jpg'), ('1460538853.jpg', 'train-cmd-839.jpg'), ('1467601507.jpg', 'train-cmd-893.jpg'), ('1472183727.jpg', 'train-cmd-1460.jpg'), ('1476112995.jpg', 'train-cbsd-227.jpg'), ('1478375260.jpg', 'train-cmd-137.jpg'), ('1479168350.jpg', 'train-cmd-1189.jpg'), ('1483777554.jpg', 'train-cmd-1235.jpg'), ('1492079032.jpg', 'train-cbsd-729.jpg'), ('15177566.jpg', 'train-cmd-374.jpg'), ('1531006450.jpg', 'train-cmd-1513.jpg'), ('1561961236.jpg', 'train-cgm-670.jpg'), ('1562043567.jpg', '3551135685.jpg'), ('1571832603.jpg', 'train-cbsd-1185.jpg'), ('1575013487.jpg', 'train-cmd-2016.jpg'), ('1575866220.jpg', 'train-cbsd-39.jpg'), ('1578897742.jpg', 'train-cmd-273.jpg'), ('1578977008.jpg', 'train-cmd-960.jpg'), ('1587009529.jpg', 'train-cmd-1264.jpg'), ('1595577438.jpg', 'train-cgm-125.jpg'), ('1595866872.jpg', 'train-cbsd-34.jpg'), ('1598187662.jpg', 'train-cmd-1332.jpg'), ('1612059624.jpg', 'train-cgm-111.jpg'), ('1612177465.jpg', 'train-cgm-432.jpg'), ('1622568975.jpg', 'train-cbsd-691.jpg'), ('162460466.jpg', 'train-cmd-1748.jpg'), ('162740748.jpg', 'train-cbsd-479.jpg'), ('1635358503.jpg', 'train-cmd-1551.jpg'), ('164781857.jpg', 'train-cmd-804.jpg'), ('1648944957.jpg', 'train-cmd-1978.jpg'), ('1650399375.jpg', 'train-cmd-1841.jpg'), ('1652157522.jpg', 'train-cbsd-137.jpg'), ('1657763940.jpg', 'train-cmd-74.jpg'), ('1666313319.jpg', 'train-cmd-996.jpg'), ('1667719250.jpg', 'train-cmd-1471.jpg'), ('1675424931.jpg', 'train-cgm-592.jpg'), ('1675758805.jpg', 'train-cmd-2358.jpg'), ('1681477511.jpg', 'train-cmd-2583.jpg'), ('1700921498.jpg', 'train-cmd-656.jpg'), ('1706377266.jpg', 'train-cbsd-671.jpg'), ('170814157.jpg', 'train-cgm-167.jpg'), ('1713444587.jpg', 'train-cgm-757.jpg'), ('171546937.jpg', 'train-cbb-193.jpg'), ('1722033032.jpg', 'train-cbb-410.jpg'), ('1724843600.jpg', 'train-cbsd-1034.jpg'), ('1726864717.jpg', 'train-cmd-298.jpg'), ('1727205281.jpg', 'train-cbsd-1016.jpg'), ('1732173388.jpg', 'train-cgm-247.jpg'), ('173849826.jpg', 'train-cgm-404.jpg'), ('1738923752.jpg', 'train-cbsd-321.jpg'), ('1747122718.jpg', 'train-cbsd-795.jpg'), ('1759147122.jpg', 'train-cmd-967.jpg'), ('177187875.jpg', 'train-cmd-1400.jpg'), ('1775105594.jpg', 'train-cmd-2191.jpg'), ('1786164172.jpg', 'train-cgm-542.jpg'), ('178880482.jpg', 'train-cmd-1067.jpg'), ('1789470358.jpg', 'train-cgm-345.jpg'), ('1792425947.jpg', 'train-cgm-764.jpg'), ('179693098.jpg', 'train-cbsd-907.jpg'), ('1814144394.jpg', 'train-cbsd-48.jpg'), ('1815147513.jpg', 'train-cbb-143.jpg'), ('1817648564.jpg', 'train-cmd-1225.jpg'), ('1818510196.jpg', 'train-cbsd-1220.jpg'), ('181857749.jpg', 'train-cgm-680.jpg'), ('1822682006.jpg', 'train-cmd-524.jpg'), ('182701414.jpg', 'train-cbsd-922.jpg'), ('1829924843.jpg', 'train-cgm-84.jpg'), ('1830481275.jpg', 'train-cbb-335.jpg'), ('183535060.jpg', 'train-cmd-1529.jpg'), ('1836918462.jpg', 'train-cbsd-1210.jpg'), ('1845811420.jpg', 'train-cgm-599.jpg'), ('1846052077.jpg', 'train-cmd-1465.jpg'), ('1859265664.jpg', 'train-cmd-1534.jpg'), ('1865586599.jpg', 'train-cbsd-112.jpg'), ('1867590389.jpg', 'train-cgm-196.jpg'), ('1875533805.jpg', 'train-cbsd-1028.jpg'), ('1876922129.jpg', 'train-cbb-365.jpg'), ('1886905036.jpg', 'train-cbb-303.jpg'), ('1889215655.jpg', 'train-cbb-299.jpg'), ('1890187078.jpg', 'train-cbsd-943.jpg'), ('189339781.jpg', 'train-cmd-2112.jpg'), ('1897585920.jpg', 'train-cmd-2420.jpg'), ('190449795.jpg', 'train-cbsd-47.jpg'), ('1907786974.jpg', 'train-cbb-272.jpg'), ('1909170813.jpg', 'train-cmd-1056.jpg'), ('1909629301.jpg', 'train-cbsd-1322.jpg'), ('1923898414.jpg', 'train-cbb-334.jpg'), ('1924122147.jpg', 'train-cmd-1580.jpg'), ('193330948.jpg', 'train-cbsd-1110.jpg'), ('1937240444.jpg', 'train-cgm-522.jpg'), ('1941569739.jpg', 'train-cbsd-593.jpg'), ('1948579246.jpg', 'train-cmd-590.jpg'), ('1958784721.jpg', 'train-cmd-955.jpg'), ('1960632681.jpg', 'train-cbsd-29.jpg'), ('1961893968.jpg', 'train-cgm-690.jpg'), ('1968165864.jpg', 'train-cmd-581.jpg'), ('1969270538.jpg', 'train-cgm-686.jpg'), ('1972732995.jpg', 'train-cmd-1675.jpg'), ('197432034.jpg', 'train-cgm-108.jpg'), ('1978570472.jpg', 'train-cmd-2638.jpg'), ('1981291103.jpg', 'train-cgm-726.jpg'), ('1983266061.jpg', 'train-cmd-1714.jpg'), ('1983607439.jpg', 'train-cmd-1048.jpg'), ('1993434265.jpg', 'train-cmd-2634.jpg'), ('1993626674.jpg', 'train-cmd-1747.jpg'), ('1995608609.jpg', 'train-cgm-115.jpg'), ('1998802568.jpg', 'train-cmd-1395.jpg'), ('2005545104.jpg', 'train-cbb-83.jpg'), ('2011856234.jpg', 'train-cmd-2057.jpg'), ('2012411582.jpg', 'train-cbsd-1391.jpg'), ('2016929365.jpg', 'train-cmd-1261.jpg'), ('2021239499.jpg', 'train-cgm-623.jpg'), ('2025224084.jpg', 'train-cmd-1231.jpg'), ('203075136.jpg', 'train-cgm-671.jpg'), ('20361463.jpg', 'train-cbsd-1032.jpg'), ('20518383.jpg', 'train-cgm-742.jpg'), ('2058684347.jpg', 'train-cgm-463.jpg'), ('2059449835.jpg', 'train-cmd-1543.jpg'), ('2066754199.jpg', 'train-cbsd-755.jpg'), ('2069885945.jpg', 'train-cbsd-921.jpg'), ('2084909272.jpg', 'train-cmd-1442.jpg'), ('2105589928.jpg', 'train-cgm-189.jpg'), ('2109494038.jpg', 'train-cmd-712.jpg'), ('2110727627.jpg', 'train-cgm-625.jpg'), ('2115508050.jpg', 'train-cmd-2262.jpg'), ('2129562481.jpg', 'train-cmd-1008.jpg'), ('2133889430.jpg', 'train-cmd-1327.jpg'), ('2139342889.jpg', 'train-cgm-314.jpg'), ('2148757008.jpg', 'train-cbsd-1285.jpg'), ('2149970580.jpg', 'train-cbb-73.jpg'), ('2161608186.jpg', 'train-cmd-1834.jpg'), ('2164751945.jpg', 'train-cmd-1259.jpg'), ('2173229407.jpg', 'train-cgm-697.jpg'), ('2177675284.jpg', 'train-cbb-361.jpg'), ('2184718270.jpg', 'train-cgm-664.jpg'), ('2186683331.jpg', 'train-cmd-686.jpg'), ('2203204324.jpg', 'train-cbb-386.jpg'), ('220707732.jpg', 'train-cgm-673.jpg'), ('2207440318.jpg', 'train-cmd-1136.jpg'), ('2208909764.jpg', 'train-cmd-2505.jpg'), ('2216899710.jpg', 'train-cmd-2482.jpg'), ('2221731773.jpg', 'train-cmd-128.jpg'), ('2221889127.jpg', 'train-cbb-19.jpg'), ('2231704125.jpg', 'train-cgm-688.jpg'), ('2232959596.jpg', 'train-cmd-2652.jpg'), ('2241394681.jpg', 'train-cgm-343.jpg'), ('2252529694.jpg', '911861181.jpg'), ('2252678193.jpg', 'train-cgm-410.jpg'), ('2260330058.jpg', 'train-cmd-112.jpg'), ('2260521441.jpg', 'train-cgm-157.jpg'), ('2264163141.jpg', 'train-cbb-355.jpg'), ('2265725202.jpg', 'train-cmd-1315.jpg'), ('226962956.jpg', 'train-cbsd-623.jpg'), ('227401382.jpg', 'train-cmd-353.jpg'), ('2308142554.jpg', 'train-cmd-782.jpg'), ('2314598518.jpg', 'train-cmd-2046.jpg'), ('2316499026.jpg', 'train-cmd-577.jpg'), ('2317623527.jpg', 'train-cmd-1853.jpg'), ('2318645335.jpg', 'train-cbb-136.jpg'), ('2328599167.jpg', 'train-cmd-1084.jpg'), ('2329316953.jpg', 'train-cmd-1229.jpg'), ('2330851012.jpg', 'train-cbsd-754.jpg'), ('2331038619.jpg', 'train-cmd-1282.jpg'), ('2332024831.jpg', 'train-cbsd-1395.jpg'), ('2338213285.jpg', 'train-cgm-543.jpg'), ('2339596137.jpg', 'train-cmd-275.jpg'), ('2344308543.jpg', 'train-cmd-1349.jpg'), ('2351508179.jpg', 'train-cmd-816.jpg'), ('2355374074.jpg', 'train-cgm-590.jpg'), ('2356810303.jpg', 'train-cmd-121.jpg'), ('2357741257.jpg', 'train-cmd-746.jpg'), ('2358762057.jpg', 'train-cmd-1138.jpg'), ('2360494692.jpg', 'train-cmd-2657.jpg'), ('2371633225.jpg', 'train-cmd-1433.jpg'), ('2380764597.jpg', 'train-cbb-41.jpg'), ('238289094.jpg', 'train-cmd-850.jpg'), ('2386253796.jpg', 'train-cmd-735.jpg'), ('2389613525.jpg', 'train-cmd-826.jpg'), ('241455389.jpg', 'train-cbsd-625.jpg'), ('2417890720.jpg', 'train-cgm-549.jpg'), ('241826799.jpg', 'train-cbb-321.jpg'), ('2418298019.jpg', 'train-cmd-842.jpg'), ('2418594163.jpg', 'train-cmd-1691.jpg'), ('2427442391.jpg', 'train-cmd-1451.jpg'), ('2430831157.jpg', 'train-cmd-1141.jpg'), ('2438313768.jpg', 'train-cgm-143.jpg'), ('2450978537.jpg', 'train-cmd-2596.jpg'), ('2467324210.jpg', 'train-cmd-539.jpg'), ('2476584583.jpg', 'train-cgm-103.jpg'), ('2481954386.jpg', 'train-cbsd-337.jpg'), ('2494764703.jpg', 'train-cgm-31.jpg'), ('2501436016.jpg', 'train-cmd-1861.jpg'), ('250907427.jpg', 'train-cbsd-329.jpg'), ('2512949736.jpg', 'train-cmd-2512.jpg'), ('2518535006.jpg', 'train-cgm-375.jpg'), ('2520781924.jpg', 'train-cmd-1167.jpg'), ('2522202499.jpg', 'train-cbsd-823.jpg'), ('2535406918.jpg', 'train-cgm-42.jpg'), ('2536424998.jpg', 'train-cbsd-285.jpg'), ('2548461545.jpg', 'train-cbb-254.jpg'), ('2549375363.jpg', 'train-cgm-226.jpg'), ('2552592093.jpg', 'train-cbb-90.jpg'), ('255823836.jpg', 'train-cbsd-1327.jpg'), ('2560468045.jpg', 'train-cmd-492.jpg'), ('2570672557.jpg', 'train-cbsd-1337.jpg'), ('2571585254.jpg', 'train-cbb-117.jpg'), ('2571818236.jpg', 'train-cmd-694.jpg'), ('2577910904.jpg', 'train-cmd-2194.jpg'), ('2582937466.jpg', 'train-cbsd-1074.jpg'), ('2588775979.jpg', 'train-cmd-2572.jpg'), ('2593976226.jpg', 'train-cbsd-868.jpg'), ('2594655853.jpg', 'train-cmd-428.jpg'), ('2595067395.jpg', 'train-cmd-2353.jpg'), ('2596761882.jpg', 'train-cmd-1924.jpg'), ('2601582697.jpg', 'train-cmd-276.jpg'), ('2606643559.jpg', 'train-cmd-792.jpg'), ('261186049.jpg', 'train-cmd-478.jpg'), ('2620149411.jpg', 'train-cbsd-742.jpg'), ('2621100310.jpg', 'train-cmd-2317.jpg'), ('2621947862.jpg', 'train-cbsd-708.jpg'), ('2627358594.jpg', 'train-cmd-1350.jpg'), ('2647070246.jpg', 'train-cgm-180.jpg'), ('2651363651.jpg', 'train-cmd-900.jpg'), ('265704323.jpg', 'train-cgm-328.jpg'), ('2657864406.jpg', 'train-cmd-631.jpg'), ('2674468156.jpg', 'train-cmd-1037.jpg'), ('2684352665.jpg', 'train-cbsd-780.jpg'), ('2689546990.jpg', 'train-cgm-54.jpg'), ('2700366371.jpg', 'train-cgm-434.jpg'), ('2711532702.jpg', 'train-cmd-2398.jpg'), ('271724485.jpg', 'train-cmd-991.jpg'), ('2722584545.jpg', 'train-cmd-1959.jpg'), ('2741057702.jpg', 'train-cbsd-930.jpg'), ('2754939037.jpg', 'train-cgm-552.jpg'), ('2759452874.jpg', 'train-cmd-2058.jpg'), ('2759500008.jpg', 'train-cmd-1851.jpg'), ('2759737963.jpg', 'train-cbsd-1070.jpg'), ('2760869322.jpg', 'train-cbsd-181.jpg'), ('2763304605.jpg', 'train-cbsd-1254.jpg'), ('2764505542.jpg', 'train-cbsd-796.jpg'), ('2764717089.jpg', 'train-cbsd-1002.jpg'), ('2766931963.jpg', 'train-cbb-307.jpg'), ('2768992642.jpg', 'train-cmd-1293.jpg'), ('278340134.jpg', 'train-cmd-537.jpg'), ('2792568356.jpg', 'train-cmd-771.jpg'), ('2813455055.jpg', 'train-cmd-1289.jpg'), ('2813897976.jpg', 'train-cbsd-1318.jpg'), ('2820203229.jpg', 'train-cmd-983.jpg'), ('2830245641.jpg', 'train-cgm-76.jpg'), ('2832996503.jpg', 'train-cbb-444.jpg'), ('2845701741.jpg', 'train-cmd-1102.jpg'), ('2847670157.jpg', 'train-cmd-1732.jpg'), ('2853035567.jpg', 'train-cmd-2175.jpg'), ('2861545981.jpg', 'train-cgm-51.jpg'), ('286515278.jpg', 'train-cmd-2571.jpg'), ('2870742473.jpg', 'train-cmd-1129.jpg'), ('2879061263.jpg', 'train-cgm-329.jpg'), ('2888640560.jpg', 'train-cgm-121.jpg'), ('289082000.jpg', 'train-cmd-1426.jpg'), ('2891895109.jpg', 'train-cmd-312.jpg'), ('2892238301.jpg', 'train-cmd-1432.jpg'), ('2902102449.jpg', 'train-cmd-299.jpg'), ('2907262343.jpg', 'train-cbb-402.jpg'), ('290867441.jpg', 'train-cbsd-1183.jpg'), ('2909347864.jpg', 'train-cmd-465.jpg'), ('2919116944.jpg', 'train-cbb-113.jpg'), ('293090840.jpg', 'train-cbsd-830.jpg'), ('2940017595.jpg', 'train-cmd-2309.jpg'), ('2941037051.jpg', 'train-cmd-2625.jpg'), ('2947092934.jpg', 'train-cbsd-636.jpg'), ('2948559947.jpg', 'train-cmd-1527.jpg'), ('2948942886.jpg', 'train-cbsd-1281.jpg'), ('2958100896.jpg', 'train-cmd-1725.jpg'), ('2963358758.jpg', 'train-cbsd-549.jpg'), ('2964066000.jpg', 'train-cmd-1624.jpg'), ('2966195606.jpg', 'train-cgm-256.jpg'), ('2967206024.jpg', 'train-cgm-458.jpg'), ('2970234083.jpg', 'train-cgm-761.jpg'), ('2972617511.jpg', 'train-cgm-703.jpg'), ('2978135052.jpg', 'train-cgm-412.jpg'), ('2983246696.jpg', 'train-cmd-87.jpg'), ('298424266.jpg', 'train-cmd-1326.jpg'), ('2985118735.jpg', 'train-cmd-2195.jpg'), ('3001382345.jpg', 'train-cbsd-251.jpg'), ('3004362957.jpg', 'train-cmd-644.jpg'), ('3006499770.jpg', 'train-cbsd-195.jpg'), ('3013471955.jpg', 'train-cmd-131.jpg'), ('3024747455.jpg', 'train-cmd-134.jpg'), ('3027691323.jpg', 'train-cgm-744.jpg'), ('3049440979.jpg', 'train-cmd-1679.jpg'), ('3054390977.jpg', 'train-cmd-1548.jpg'), ('3058038323.jpg', 'train-cmd-1443.jpg'), ('3058256804.jpg', 'train-cmd-2526.jpg'), ('306133807.jpg', 'train-cmd-293.jpg'), ('3073409707.jpg', 'train-cmd-2589.jpg'), ('3082163001.jpg', 'train-cmd-1025.jpg'), ('3097440014.jpg', 'train-cbb-225.jpg'), ('3100925014.jpg', 'train-cgm-170.jpg'), ('3114522519.jpg', 'train-cmd-1230.jpg'), ('3116498490.jpg', 'train-cbb-38.jpg'), ('3126447146.jpg', 'train-cmd-2588.jpg'), ('3132206324.jpg', 'train-cgm-257.jpg'), ('3135130073.jpg', 'train-cmd-1895.jpg'), ('3141049473.jpg', 'train-cmd-2377.jpg'), ('3146983924.jpg', 'train-cmd-1636.jpg'), ('3151955638.jpg', 'train-cgm-402.jpg'), ('3153618395.jpg', 'train-cmd-865.jpg'), ('3164836946.jpg', 'train-cbsd-10.jpg'), ('3175363969.jpg', 'train-cbb-220.jpg'), ('3181600056.jpg', 'train-cgm-718.jpg'), ('3182736637.jpg', 'train-cgm-73.jpg'), ('3185750323.jpg', 'train-cgm-566.jpg'), ('3188097509.jpg', 'train-cgm-230.jpg'), ('3188727997.jpg', 'train-cmd-542.jpg'), ('318991539.jpg', 'train-cmd-1749.jpg'), ('3194661838.jpg', 'train-cmd-2394.jpg'), ('3199430859.jpg', 'train-cmd-1696.jpg'), ('3201556287.jpg', 'train-cmd-1019.jpg'), ('3214730186.jpg', 'train-cbb-279.jpg'), ('3216675047.jpg', 'train-cmd-1610.jpg'), ('3228239886.jpg', 'train-cbb-79.jpg'), ('3229179609.jpg', 'train-cbsd-1094.jpg'), ('3237922501.jpg', 'train-cgm-295.jpg'), ('3252706161.jpg', 'train-cmd-2143.jpg'), ('3259397427.jpg', 'train-cmd-1920.jpg'), ('3262221593.jpg', 'train-cbb-122.jpg'), ('3267041557.jpg', 'train-cbsd-1029.jpg'), ('3268898958.jpg', 'train-cgm-187.jpg'), ('3269286573.jpg', 'train-cmd-408.jpg'), ('3279881598.jpg', 'train-cbb-36.jpg'), ('328959114.jpg', 'train-cgm-205.jpg'), ('3289998998.jpg', 'train-cmd-2594.jpg'), ('3290949725.jpg', 'train-cbb-346.jpg'), ('3293589198.jpg', 'train-cbsd-183.jpg'), ('3294433487.jpg', 'train-cbsd-1173.jpg'), ('3296434764.jpg', 'train-cmd-1940.jpg'), ('3314463308.jpg', 'train-cmd-1519.jpg'), ('3315868108.jpg', 'train-cgm-50.jpg'), ('3315979770.jpg', 'train-cmd-1765.jpg'), ('3325565280.jpg', 'train-cmd-84.jpg'), ('3331347285.jpg', 'train-cgm-0.jpg'), ('3335254269.jpg', 'train-cbsd-349.jpg'), ('3341146922.jpg', 'train-cmd-237.jpg'), ('3341233301.jpg', 'train-cmd-877.jpg'), ('3343675403.jpg', 'train-cmd-1812.jpg'), ('3345498406.jpg', 'train-cmd-2236.jpg'), ('3347545196.jpg', 'train-cbsd-634.jpg'), ('3350687852.jpg', 'train-cmd-290.jpg'), ('3358660933.jpg', 'train-cmd-1511.jpg'), ('3370367169.jpg', 'train-cgm-162.jpg'), ('3384415464.jpg', 'train-cgm-119.jpg'), ('3385144102.jpg', 'train-cgm-370.jpg'), ('3385309388.jpg', 'train-cbsd-62.jpg'), ('3390516449.jpg', 'train-cmd-333.jpg'), ('3395914437.jpg', 'train-cgm-309.jpg'), ('3397650599.jpg', 'train-cbb-221.jpg'), ('3408364070.jpg', 'train-cmd-903.jpg'), ('3408460296.jpg', 'train-cmd-1911.jpg'), ('3411831481.jpg', 'train-cmd-691.jpg'), ('3413715358.jpg', 'train-cgm-528.jpg'), ('3424307098.jpg', 'train-cmd-1907.jpg'), ('3424618786.jpg', 'train-cmd-380.jpg'), ('342796483.jpg', 'train-cmd-217.jpg'), ('343990809.jpg', 'train-cbsd-336.jpg'), ('3441163294.jpg', 'train-cmd-2155.jpg'), ('3451340587.jpg', 'train-cmd-2489.jpg'), ('3457494065.jpg', 'train-cgm-264.jpg'), ('3458199144.jpg', 'train-cmd-652.jpg'), ('3462014192.jpg', 'train-cgm-748.jpg'), ('3474522679.jpg', 'train-cbsd-1011.jpg'), ('3476081387.jpg', 'train-cbb-282.jpg'), ('3489790909.jpg', 'train-cbsd-1286.jpg'), ('3492066669.jpg', 'train-cmd-1330.jpg'), ('3505403837.jpg', 'train-cmd-1567.jpg'), ('3506364620.jpg', 'train-cbsd-275.jpg'), ('3511671285.jpg', 'train-cbsd-1240.jpg'), ('3521763231.jpg', 'train-cbsd-1421.jpg'), ('3523363514.jpg', 'train-cmd-2140.jpg'), ('3538242745.jpg', 'train-cbsd-595.jpg'), ('3540055410.jpg', 'train-cmd-871.jpg'), ('3542768898.jpg', 'train-cmd-624.jpg'), ('3546777867.jpg', 'train-cgm-113.jpg'), ('3552298032.jpg', 'train-cmd-1448.jpg'), ('3561701886.jpg', 'train-cgm-505.jpg'), ('3566226674.jpg', 'train-cmd-2523.jpg'), ('3576823132.jpg', 'train-cgm-333.jpg'), ('3579018611.jpg', 'train-cgm-445.jpg'), ('3580388018.jpg', 'train-cmd-674.jpg'), ('35875939.jpg', 'train-cmd-2055.jpg'), ('358823158.jpg', 'train-cmd-1427.jpg'), ('3594689734.jpg', 'train-cbsd-1087.jpg'), ('3606759049.jpg', 'train-cbsd-66.jpg'), ('3608078575.jpg', 'train-cmd-2401.jpg'), ('3610820560.jpg', 'train-cgm-722.jpg'), ('3626400961.jpg', 'train-cmd-1757.jpg'), ('3630015138.jpg', 'train-cbb-72.jpg'), ('3632711020.jpg', 'train-cmd-2050.jpg'), ('3637416250.jpg', 'train-cbsd-107.jpg'), ('3638122648.jpg', 'train-cmd-211.jpg'), ('3645245816.jpg', 'train-cgm-363.jpg'), ('3649285117.jpg', 'train-cbsd-437.jpg'), ('3651958252.jpg', 'train-cmd-2491.jpg'), ('366195058.jpg', 'train-cmd-1296.jpg'), ('3667237103.jpg', 'train-cmd-545.jpg'), ('368553798.jpg', 'train-cmd-1908.jpg'), ('3688529022.jpg', 'train-cmd-2204.jpg'), ('369175053.jpg', 'train-cbsd-1316.jpg'), ('3691870719.jpg', 'train-cmd-2390.jpg'), ('369451134.jpg', 'train-cmd-1062.jpg'), ('3696011777.jpg', 'train-cmd-2502.jpg'), ('3698876668.jpg', 'train-cmd-846.jpg'), ('3708168447.jpg', 'train-cmd-283.jpg'), ('3708517022.jpg', 'train-cmd-1870.jpg'), ('3718347785.jpg', 'train-cmd-1919.jpg'), ('3722626623.jpg', 'train-cmd-1200.jpg'), ('3727359090.jpg', 'train-cgm-268.jpg'), ('3731008076.jpg', 'train-cbb-60.jpg'), ('3731052059.jpg', 'train-cbsd-1398.jpg'), ('3731328789.jpg', 'train-cmd-522.jpg'), ('3741620114.jpg', 'train-cmd-1875.jpg'), ('3752575686.jpg', 'train-cmd-1196.jpg'), ('3755456249.jpg', 'train-cmd-2128.jpg'), ('3770952591.jpg', 'train-cbsd-697.jpg'), ('3772064912.jpg', 'train-cgm-519.jpg'), ('3775082960.jpg', 'train-cbb-310.jpg'), ('3781670038.jpg', 'train-cgm-78.jpg'), ('3782909126.jpg', 'train-cbsd-837.jpg'), ('3785055674.jpg', 'train-cmd-622.jpg'), ('378894822.jpg', 'train-cmd-360.jpg'), ('379373523.jpg', 'train-cgm-323.jpg'), ('37954651.jpg', 'train-cmd-1705.jpg'), ('3809163419.jpg', 'train-cbb-382.jpg'), ('3810740135.jpg', 'train-cmd-2034.jpg'), ('3813835902.jpg', 'train-cgm-154.jpg'), ('3816048744.jpg', 'train-cbsd-1221.jpg'), ('3821611662.jpg', 'train-cbsd-353.jpg'), ('3826775864.jpg', 'train-cgm-503.jpg'), ('3829488807.jpg', 'train-cmd-105.jpg'), ('3833092976.jpg', 'train-cmd-1013.jpg'), ('3837689204.jpg', 'train-cmd-447.jpg'), ('3838205917.jpg', 'train-cmd-1796.jpg'), ('383932080.jpg', 'train-cbb-97.jpg'), ('384122684.jpg', 'train-cmd-1729.jpg'), ('3847172492.jpg', 'train-cmd-2460.jpg'), ('3848558113.jpg', 'train-cmd-517.jpg'), ('3848622850.jpg', 'train-cmd-1947.jpg'), ('3856769685.jpg', 'train-cmd-2474.jpg'), ('385685508.jpg', 'train-cbsd-305.jpg'), ('3859028489.jpg', 'train-cgm-8.jpg'), ('3876777651.jpg', 'train-cmd-1912.jpg'), ('3892133252.jpg', 'train-cgm-675.jpg'), ('3894262995.jpg', 'train-cmd-1958.jpg'), ('3903538298.jpg', 'train-cmd-2170.jpg'), ('3905302037.jpg', 'train-cbb-308.jpg'), ('391259058.jpg', 'train-cbsd-287.jpg'), ('3912926258.jpg', 'train-cgm-487.jpg'), ('3921328805.jpg', 'train-cbsd-872.jpg'), ('3924602971.jpg', 'train-cbsd-1106.jpg'), ('392503327.jpg', 'train-cbsd-1325.jpg'), ('3930711994.jpg', 'train-cmd-2214.jpg'), ('3938349285.jpg', 'train-cbb-275.jpg'), ('3943325497.jpg', 'train-cmd-296.jpg'), ('3946178245.jpg', 'train-cbsd-1099.jpg'), ('3948333262.jpg', 'train-cmd-1246.jpg'), ('3951364046.jpg', 'train-cmd-195.jpg'), ('3951384519.jpg', 'train-cmd-502.jpg'), ('3953222407.jpg', 'train-cgm-608.jpg'), ('3958304403.jpg', 'train-cbsd-679.jpg'), ('3963572251.jpg', 'train-cgm-622.jpg'), ('3966256467.jpg', 'train-cbb-437.jpg'), ('3968384941.jpg', 'train-cgm-589.jpg'), ('3974310104.jpg', 'train-cbb-259.jpg'), ('397477697.jpg', 'train-cgm-546.jpg'), ('3978633568.jpg', 'train-cmd-1017.jpg'), ('3995159118.jpg', 'train-cmd-473.jpg'), ('4014877464.jpg', 'train-cmd-1142.jpg'), ('4024391744.jpg', 'train-cgm-5.jpg'), ('4031122706.jpg', 'train-cmd-1154.jpg'), ('4031188863.jpg', 'train-cmd-2259.jpg'), ('403372857.jpg', 'train-cbb-255.jpg'), ('403458333.jpg', 'train-cbsd-147.jpg'), ('4038344014.jpg', 'train-cmd-2590.jpg'), ('4048486399.jpg', 'train-cmd-1360.jpg'), ('4048519217.jpg', 'train-cbsd-238.jpg'), ('405720625.jpg', 'train-cmd-2.jpg'), ('4059451569.jpg', 'train-cbsd-840.jpg'), ('4071582691.jpg', 'train-cmd-1244.jpg'), ('4079242692.jpg', 'train-cgm-275.jpg'), ('4083768019.jpg', 'train-cbb-155.jpg'), ('4088249542.jpg', 'train-cbb-100.jpg'), ('4091663475.jpg', 'train-cbb-414.jpg'), ('409474529.jpg', 'train-cmd-429.jpg'), ('4098473118.jpg', 'train-cmd-2519.jpg'), ('4103177818.jpg', 'train-cmd-676.jpg'), ('4103428960.jpg', 'train-cgm-535.jpg'), ('4110644267.jpg', 'train-cgm-563.jpg'), ('4111161962.jpg', 'train-cbsd-681.jpg'), ('4121231239.jpg', 'train-cgm-497.jpg'), ('4141439714.jpg', 'train-cmd-253.jpg'), ('4141594059.jpg', 'train-cmd-1032.jpg'), ('414320641.jpg', 'train-cbsd-187.jpg'), ('4145051602.jpg', 'train-cmd-1014.jpg'), ('4146091086.jpg', 'train-cbsd-622.jpg'), ('4161605185.jpg', 'train-cmd-1577.jpg'), ('4166762.jpg', 'train-cmd-382.jpg'), ('4170665280.jpg', 'train-cmd-482.jpg'), ('417083161.jpg', 'train-cgm-169.jpg'), ('4183077936.jpg', 'train-cmd-2604.jpg'), ('4183078751.jpg', 'train-cmd-1352.jpg'), ('4186901068.jpg', 'train-cmd-70.jpg'), ('4211138249.jpg', 'train-cmd-822.jpg'), ('4222515459.jpg', 'train-cmd-458.jpg'), ('4230605387.jpg', 'train-cgm-71.jpg'), ('423288187.jpg', 'train-cbb-161.jpg'), ('4243169950.jpg', 'train-cgm-91.jpg'), ('4248343921.jpg', 'train-cbsd-1123.jpg'), ('4250538490.jpg', 'train-cbsd-1358.jpg'), ('4254213032.jpg', 'train-cgm-48.jpg'), ('4255100884.jpg', 'train-cmd-1453.jpg'), ('4287369745.jpg', 'train-cmd-67.jpg'), ('4290607578.jpg', 'train-cmd-1446.jpg'), ('4292224219.jpg', 'train-cmd-2123.jpg'), ('431411749.jpg', 'train-cbsd-1442.jpg'), ('437958298.jpg', 'train-cbsd-292.jpg'), ('446546740.jpg', 'train-cmd-1918.jpg'), ('456001532.jpg', 'train-cmd-167.jpg'), ('469487.jpg', 'train-cbsd-323.jpg'), ('483398598.jpg', 'train-cmd-96.jpg'), ('51063556.jpg', 'train-cmd-1560.jpg'), ('514376645.jpg', 'train-cmd-2047.jpg'), ('519050764.jpg', 'train-cbb-129.jpg'), ('537771989.jpg', 'train-cmd-1430.jpg'), ('546931175.jpg', 'train-cgm-199.jpg'), ('554118057.jpg', 'train-cmd-1686.jpg'), ('560592460.jpg', 'train-cgm-716.jpg'), ('561647799.jpg', 'train-cbsd-80.jpg'), ('562027159.jpg', 'train-cgm-248.jpg'), ('579336785.jpg', 'train-cmd-1738.jpg'), ('586116935.jpg', 'train-cgm-770.jpg'), ('594027454.jpg', 'train-cbsd-1319.jpg'), ('598311175.jpg', 'train-cmd-864.jpg'), ('599325048.jpg', 'train-cbb-418.jpg'), ('610094717.jpg', 'train-cmd-504.jpg'), ('61492497.jpg', 'train-cmd-639.jpg'), ('620126996.jpg', 'train-cgm-368.jpg'), ('630240307.jpg', 'train-cmd-2514.jpg'), ('632236115.jpg', 'train-cbsd-1222.jpg'), ('643956994.jpg', 'train-cgm-399.jpg'), ('64732457.jpg', 'train-cmd-2553.jpg'), ('659495074.jpg', 'train-cbsd-381.jpg'), ('660715584.jpg', 'train-cmd-425.jpg'), ('66458318.jpg', 'train-cbsd-426.jpg'), ('664583876.jpg', 'train-cgm-712.jpg'), ('667282886.jpg', 'train-cmd-1288.jpg'), ('674360414.jpg', 'train-cbsd-23.jpg'), ('680272982.jpg', 'train-cmd-1814.jpg'), ('700113045.jpg', 'train-cmd-2432.jpg'), ('702121018.jpg', 'train-cbsd-22.jpg'), ('704115558.jpg', 'train-cbsd-156.jpg'), ('705481569.jpg', 'train-cmd-1276.jpg'), ('707255804.jpg', 'train-cmd-1944.jpg'), ('724059503.jpg', 'train-cmd-567.jpg'), ('728569501.jpg', 'train-cmd-60.jpg'), ('745135323.jpg', 'train-cbsd-1216.jpg'), ('746879421.jpg', 'train-cbb-142.jpg'), ('755437879.jpg', 'train-cmd-2014.jpg'), ('762558370.jpg', 'train-cmd-1579.jpg'), ('773130398.jpg', 'train-cmd-483.jpg'), ('774801310.jpg', 'train-cmd-832.jpg'), ('777180004.jpg', 'train-cgm-352.jpg'), ('787756871.jpg', 'train-cmd-1412.jpg'), ('797094434.jpg', 'train-cmd-725.jpg'), ('807190211.jpg', 'train-cmd-1795.jpg'), ('816689138.jpg', 'train-cmd-2413.jpg'), ('823298994.jpg', 'train-cbsd-519.jpg'), ('843483418.jpg', 'train-cbsd-1299.jpg'), ('867127390.jpg', 'train-cbsd-1150.jpg'), ('868228069.jpg', 'train-cmd-2364.jpg'), ('872498616.jpg', 'train-cbb-393.jpg'), ('881299929.jpg', 'train-cmd-1238.jpg'), ('888266861.jpg', 'train-cbsd-451.jpg'), ('891320496.jpg', 'train-cbsd-1383.jpg'), ('897745173.jpg', 'train-cmd-91.jpg'), ('899398361.jpg', 'train-cmd-2520.jpg'), ('918605153.jpg', 'train-cgm-446.jpg'), ('930097123.jpg', 'train-cmd-749.jpg'), ('939861475.jpg', 'train-cmd-115.jpg'), ('945680317.jpg', 'train-cmd-55.jpg'), ('96041444.jpg', 'train-cbsd-1120.jpg'), ('963176335.jpg', 'train-cmd-944.jpg'), ('980448273.jpg', 'train-cbsd-758.jpg'), ('980911264.jpg', 'train-cmd-617.jpg'), ('981946821.jpg', 'train-cmd-2547.jpg'), ('988174802.jpg', 'train-cbb-149.jpg'), ('996534381.jpg', 'train-cbsd-331.jpg'), ('train-cbb-115.jpg', 'train-cbsd-656.jpg'), ('train-cbb-213.jpg', 'train-cgm-321.jpg'), ('train-cbb-216.jpg', 'train-cgm-687.jpg'), ('train-cbb-244.jpg', 'train-cbsd-632.jpg'), ('train-cbb-247.jpg', 'train-cbsd-328.jpg'), ('train-cbb-306.jpg', 'train-cbsd-931.jpg'), ('train-cbb-317.jpg', 'train-cbsd-240.jpg'), ('train-cbb-371.jpg', 'train-cbb-427.jpg'), ('train-cbb-371.jpg', 'train-cbb-94.jpg'), ('train-cbb-374.jpg', 'train-cgm-698.jpg'), ('train-cbb-381.jpg', 'train-cbsd-216.jpg'), ('train-cbb-405.jpg', 'train-cgm-246.jpg'), ('train-cbb-427.jpg', 'train-cbb-94.jpg'), ('train-cbsd-1033.jpg', 'train-cbsd-352.jpg'), ('train-cbsd-1046.jpg', 'train-cgm-253.jpg'), ('train-cbsd-1051.jpg', 'train-cbsd-1101.jpg'), ('train-cbsd-1172.jpg', 'train-cbsd-358.jpg'), ('train-cbsd-12.jpg', 'train-cbsd-1297.jpg'), ('train-cbsd-1246.jpg', 'train-cbsd-138.jpg'), ('train-cbsd-1246.jpg', 'train-cbsd-654.jpg'), ('train-cbsd-1354.jpg', 'train-cgm-455.jpg'), ('train-cbsd-138.jpg', 'train-cbsd-654.jpg'), ('train-cbsd-1419.jpg', 'train-cgm-279.jpg'), ('train-cbsd-143.jpg', 'train-cbsd-661.jpg'), ('train-cbsd-17.jpg', 'train-cbsd-713.jpg'), ('train-cbsd-173.jpg', 'train-cbsd-978.jpg'), ('train-cbsd-174.jpg', 'train-cbsd-243.jpg'), ('train-cbsd-193.jpg', 'train-cbsd-304.jpg'), ('train-cbsd-233.jpg', 'train-cbsd-270.jpg'), ('train-cbsd-257.jpg', 'train-cbsd-650.jpg'), ('train-cbsd-277.jpg', 'train-cbsd-610.jpg'), ('train-cbsd-421.jpg', 'train-cbsd-985.jpg'), ('train-cbsd-481.jpg', 'train-cmd-477.jpg'), ('train-cbsd-513.jpg', 'train-cbsd-530.jpg'), ('train-cbsd-533.jpg', 'train-cbsd-785.jpg'), ('train-cbsd-660.jpg', 'train-healthy-50.jpg'), ('train-cbsd-661.jpg', 'train-cbsd-717.jpg'), ('train-cbsd-666.jpg', 'train-cgm-166.jpg'), ('train-cbsd-791.jpg', 'train-cgm-90.jpg'), ('train-cgm-304.jpg', 'train-cgm-760.jpg'), ('train-cgm-396.jpg', 'train-cgm-477.jpg'), ('train-cgm-396.jpg', 'train-cgm-565.jpg'), ('train-cgm-437.jpg', 'train-cgm-652.jpg'), ('train-cgm-477.jpg', 'train-cgm-565.jpg'), ('train-cmd-1150.jpg', 'train-cmd-2167.jpg'), ('train-cmd-1165.jpg', 'train-cmd-186.jpg'), ('train-cmd-1165.jpg', 'train-cmd-450.jpg'), ('train-cmd-1248.jpg', 'train-cmd-444.jpg'), ('train-cmd-149.jpg', 'train-cmd-582.jpg'), ('train-cmd-153.jpg', 'train-cmd-1648.jpg'), ('train-cmd-1600.jpg', 'train-cmd-1771.jpg'), ('train-cmd-1600.jpg', 'train-cmd-1894.jpg'), ('train-cmd-1771.jpg', 'train-cmd-1894.jpg'), ('train-cmd-2003.jpg', 'train-cmd-966.jpg'), ('train-cmd-220.jpg', 'train-cmd-2431.jpg'), ('train-cmd-2302.jpg', 'train-cmd-2399.jpg'), ('train-cmd-2451.jpg', 'train-healthy-149.jpg'), ('train-healthy-136.jpg', 'train-healthy-77.jpg')]\n",
    "\n",
    "    # duplicates: 2020 only (DBSCAN)\n",
    "    #duplicates += [('2947932468.jpg', '2385382730.jpg'), ('2252529694.jpg', '911861181.jpg'), ('2278017076.jpg', '3518916516.jpg'), ('846123439.jpg', '718269749.jpg'), ('1562043567.jpg', '3551135685.jpg'), ('3551135685.jpg', '1562043567.jpg')]\n",
    "    \n",
    "    # duplicates: all data with DBSCAN\n",
    "    duplicates   = [['extra-image-1540.jpg', '3286430972.jpg'], ['extra-image-5393.jpg', '1007196516.jpg'], ['extra-image-9233.jpg', '177429020.jpg'], ['extra-image-11388.jpg', '401103417.jpg'], ['extra-image-4308.jpg', '2293657925.jpg'], ['train-cbsd-216.jpg', 'train-cbb-381.jpg', 'test-img-1450.jpg'], ['train-cgm-90.jpg', 'train-cbsd-791.jpg', 'test-img-2051.jpg'], ['extra-image-1924.jpg', '1710187645.jpg'], ['extra-image-5502.jpg', '3513881408.jpg'], ['extra-image-2527.jpg', '4080972605.jpg'], ['extra-image-5475.jpg', '2309908274.jpg'], ['extra-image-428.jpg', '490262929.jpg'], ['train-cgm-373.jpg', 'test-img-3468.jpg'], ['train-cbsd-123.jpg', 'test-img-1610.jpg'], ['extra-image-549.jpg', '2259763259.jpg'], ['extra-image-6922.jpg', 'extra-image-12476.jpg', '825340900.jpg'], ['extra-image-2618.jpg', '1318419572.jpg'], ['extra-image-7208.jpg', 'extra-image-109.jpg', '1273363177.jpg'], ['extra-image-11114.jpg', '1618418212.jpg'], ['test-img-1455.jpg', '4016154109.jpg'], ['extra-image-563.jpg', '3789300725.jpg'], ['train-cmd-2506.jpg', 'train-cmd-1997.jpg', 'test-img-1792.jpg'], ['extra-image-15978.jpg', '1720773250.jpg'], ['train-cmd-366.jpg', 'test-img-3080.jpg'], ['extra-image-2732.jpg', '490603548.jpg'], ['extra-image-14790.jpg', 'extra-image-12199.jpg'], ['train-cmd-900.jpg', '2651363651.jpg'], ['extra-image-933.jpg', '479472063.jpg'], ['extra-image-6992.jpg', '3676057452.jpg'], ['532464272.jpg', '3361673129.jpg'], ['extra-image-10457.jpg', '3118293114.jpg'], ['extra-image-633.jpg', '3069603925.jpg'], ['train-cgm-563.jpg', '4110644267.jpg'], ['extra-image-1372.jpg', '1466391339.jpg'], ['train-cbb-282.jpg', '3476081387.jpg'], ['extra-image-4289.jpg', '2333536768.jpg'], ['extra-image-9788.jpg', '1558894441.jpg'], ['extra-image-9728.jpg', '2704051934.jpg'], ['3507045403.jpg', '2243541656.jpg'], ['extra-image-9779.jpg', '1719304067.jpg'], ['extra-image-3139.jpg', '3361179403.jpg'], ['extra-image-15471.jpg', '1621255319.jpg'], ['extra-image-11326.jpg', '3647124621.jpg'], ['extra-image-6559.jpg', '2519536403.jpg'], ['extra-image-14943.jpg', '952303505.jpg'], ['train-cbsd-1150.jpg', '867127390.jpg'], ['extra-image-5923.jpg', '1091727259.jpg'], ['train-cmd-2170.jpg', '3903538298.jpg'], ['extra-image-12924.jpg', '1131959133.jpg'], ['extra-image-13477.jpg', '2904848270.jpg'], ['extra-image-3871.jpg', '4059169921.jpg'], ['extra-image-4513.jpg', '3662840429.jpg'], ['extra-image-4605.jpg', '232710623.jpg'], ['extra-image-9217.jpg', '1200108798.jpg'], ['extra-image-2419.jpg', '690440568.jpg', '3803823261.jpg'], ['extra-image-12887.jpg', '1989789271.jpg'], ['3251960666.jpg', '2925605732.jpg', '1770746162.jpg'], ['extra-image-4112.jpg', '800250438.jpg'], ['extra-image-10326.jpg', '2888967355.jpg'], ['train-cmd-2615.jpg', 'test-img-3118.jpg'], ['test-img-2592.jpg', '943110824.jpg'], ['extra-image-9616.jpg', '1332855741.jpg'], ['test-img-998.jpg', '58720038.jpg'], ['extra-image-5076.jpg', '2801552324.jpg'], ['extra-image-9334.jpg', '4245562546.jpg'], ['extra-image-12355.jpg', '185236448.jpg'], ['extra-image-5576.jpg', '1761795923.jpg'], ['extra-image-7798.jpg', '3148313410.jpg'], ['train-cgm-8.jpg', '3859028489.jpg'], ['extra-image-13482.jpg', '426528709.jpg'], ['extra-image-12337.jpg', '4089645917.jpg'], ['extra-image-6633.jpg', '2437547294.jpg'], ['extra-image-2857.jpg', '2246452498.jpg'], ['extra-image-590.jpg', '3677086623.jpg'], ['extra-image-10042.jpg', '169189292.jpg'], ['extra-image-8920.jpg', 'extra-image-2601.jpg'], ['extra-image-4990.jpg', '4138769021.jpg'], ['train-cbsd-1437.jpg', 'test-img-3607.jpg', 'test-img-2634.jpg'], ['train-cmd-2459.jpg', 'test-img-698.jpg', 'test-img-3742.jpg', 'test-img-2354.jpg'], ['test-img-1194.jpg', '1007700625.jpg'], ['extra-image-5652.jpg', '3418761424.jpg'], ['extra-image-12886.jpg', '1529177483.jpg'], ['588169966.jpg', '1733354827.jpg'], ['train-cmd-2102.jpg', 'train-cmd-2045.jpg', 'train-cmd-1076.jpg', 'test-img-183.jpg'], ['test-img-3037.jpg', '2760272941.jpg'], ['extra-image-6996.jpg', '3258193135.jpg'], ['extra-image-10309.jpg', '19872828.jpg', '1796762442.jpg'], ['train-cmd-790.jpg', 'train-cmd-2355.jpg'], ['extra-image-9742.jpg', '3132128369.jpg'], ['extra-image-7929.jpg', '2828723686.jpg'], ['extra-image-14835.jpg', '744619434.jpg'], ['extra-image-8184.jpg', '3198115498.jpg'], ['extra-image-15188.jpg', '239700501.jpg'], ['extra-image-3641.jpg', '1694968228.jpg'], ['extra-image-4976.jpg', '1660551148.jpg'], ['test-img-1767.jpg', 'test-img-1219.jpg'], ['extra-image-2468.jpg', '4195598174.jpg'], ['extra-image-12556.jpg', '3889376143.jpg'], ['extra-image-1563.jpg', '1803055979.jpg'], ['extra-image-2068.jpg', '1089759212.jpg'], ['extra-image-8657.jpg', '3055297068.jpg'], ['extra-image-5237.jpg', '245076718.jpg'], ['extra-image-11168.jpg', '3354494955.jpg'], ['extra-image-12603.jpg', '4134659314.jpg'], ['extra-image-16033.jpg', '597389720.jpg'], ['extra-image-14012.jpg', '4234497061.jpg'], ['test-img-138.jpg', '3884189662.jpg'], ['extra-image-1992.jpg', '1982702143.jpg'], ['extra-image-5798.jpg', '3048105792.jpg'], ['test-img-439.jpg', '2259667328.jpg'], ['test-img-1145.jpg', '1356659344.jpg'], ['extra-image-9462.jpg', '3826670209.jpg'], ['extra-image-456.jpg', '945966296.jpg'], ['train-cbb-129.jpg', '519050764.jpg'], ['extra-image-12241.jpg', '2876852928.jpg'], ['extra-image-13234.jpg', '1973109559.jpg'], ['extra-image-6232.jpg', '2659874728.jpg'], ['extra-image-3883.jpg', '2086525919.jpg'], ['extra-image-12735.jpg', '1263625799.jpg'], ['extra-image-2704.jpg', 'extra-image-12619.jpg', '534364866.jpg'], ['extra-image-7008.jpg', '459566440.jpg'], ['extra-image-771.jpg', '1893842412.jpg'], ['extra-image-4438.jpg', '3036253841.jpg'], ['extra-image-6310.jpg', '1663857014.jpg'], ['extra-image-10771.jpg', '1435171668.jpg'], ['extra-image-6392.jpg', '2305895487.jpg'], ['extra-image-8649.jpg', '1831389246.jpg'], ['extra-image-11953.jpg', '1043857809.jpg'], ['test-img-242.jpg', 'test-img-2340.jpg'], ['extra-image-2434.jpg', '234486821.jpg'], ['extra-image-11518.jpg', '1465774459.jpg'], ['extra-image-2589.jpg', '671675016.jpg'], ['extra-image-11209.jpg', '3051541520.jpg'], ['extra-image-7346.jpg', '4070631340.jpg'], ['extra-image-652.jpg', '3746679490.jpg'], ['extra-image-14165.jpg', '2008776850.jpg'], ['extra-image-8273.jpg', '2181262010.jpg'], ['extra-image-6930.jpg', '3649693860.jpg'], ['test-img-3350.jpg', '3709602808.jpg'], ['extra-image-14435.jpg', '2976631036.jpg'], ['extra-image-1152.jpg', '3304610004.jpg'], ['extra-image-4709.jpg', '2810787386.jpg'], ['train-cmd-1507.jpg', 'test-img-33.jpg', 'test-img-235.jpg'], ['extra-image-15422.jpg', '1381973639.jpg'], ['extra-image-2259.jpg', '1061187521.jpg'], ['extra-image-9075.jpg', '2356938780.jpg'], ['extra-image-4587.jpg', '1160018036.jpg'], ['extra-image-14543.jpg', '138109251.jpg'], ['extra-image-9167.jpg', '2583894106.jpg'], ['extra-image-4718.jpg', '1297475127.jpg'], ['extra-image-14501.jpg', '2435784137.jpg'], ['extra-image-13365.jpg', '2126921679.jpg'], ['extra-image-3186.jpg', '324248837.jpg'], ['extra-image-3175.jpg', '1820923810.jpg'], ['421035788.jpg', '1008244905.jpg'], ['extra-image-8581.jpg', '4153074724.jpg'], ['extra-image-5561.jpg', '408051106.jpg'], ['extra-image-6928.jpg', '2396550881.jpg'], ['extra-image-9250.jpg', '3407709856.jpg'], ['train-cbsd-251.jpg', '3001382345.jpg'], ['extra-image-15574.jpg', '726377415.jpg']]\n",
    "    false_images = ['train-cmd-2506.jpg', 'extra-image-14790.jpg', '53246272.jpg', '3507045403.jpg', 'test-img-3607.jpg', '19872828.jpg', 'extra-image-2619.jpg']\n",
    "    \n",
    "    # convert to duplicate list\n",
    "    list_dupl = []\n",
    "    for row in duplicates:\n",
    "        list_dupl += row[:-1]\n",
    "    list_dupl = list(set(list_dupl))\n",
    "    list_dupl = [l for l in list_dupl if l not in false_images]\n",
    "    del duplicates\n",
    "    print('No. duplicate images:', len(list_dupl))\n",
    "\n",
    "\n",
    "##### OUTLIERS\n",
    "\n",
    "if CFG['drop_outs']:\n",
    "\n",
    "    list_outs = ['1033403106.jpg', '104535906.jpg', '1084966463.jpg', '1200108798.jpg', '1230982659.jpg', '1234375577.jpg', '1329083657.jpg', '133263895.jpg', '1395513159.jpg', '1541808301.jpg', '1576487452.jpg', '1635136764.jpg', '1689108113.jpg', '1765374655.jpg', \n",
    "                 '1841279687.jpg', '1870791731.jpg', '1894675387.jpg', '2052899282.jpg', '2151050324.jpg', '2298308938.jpg', '2321669192.jpg', '2378878506.jpg', '2504430507.jpg', '2642216511.jpg', '2666462236.jpg', '2719114674.jpg', '2739645903.jpg', '2786559298.jpg', \n",
    "                 '2853279464.jpg', '2889965946.jpg', '2967206024.jpg', '2968477250.jpg', '3002089936.jpg', '3212523761.jpg', '3238801760.jpg', '3250352507.jpg', '3267697264.jpg', '3433580973.jpg', '3806787164.jpg', '4196928486.jpg', '4250554784.jpg', '456647345.jpg', \n",
    "                 '479609263.jpg', '511494516.jpg', '534270890.jpg', '587829607.jpg', '65139094.jpg', '690440568.jpg', '74966012.jpg', '854773586.jpg', 'train-cmd-328.jpg', 'train-cbsd-319.jpg', 'train-cgm-223.jpg', 'train-cgm-190.jpg', 'train-cmd-1479.jpg']\n",
    "    print('No. outlier images:', len(list_outs))\n",
    "\n",
    "\n",
    "##### NOISY IMAGES\n",
    "\n",
    "##### NOISY IMAGES\n",
    "\n",
    "if (CFG['drop_noise']) or (CFG['flip_noise']):\n",
    "\n",
    "    # import\n",
    "    df_no = pd.read_csv(CFG['data_path'] + 'oof_median.csv')\n",
    "\n",
    "    # filter confident predictions\n",
    "    df_no['pred']      = np.argmax(df_no[['c0', 'c1', 'c2', 'c3', 'c4']].values, axis = 1)\n",
    "    df_no['confidence'] = df_no[['c0', 'c1', 'c2', 'c3', 'c4']].max(axis = 1)\n",
    "    df_no = df_no.loc[df_no['pred'] != df_no['label']].reset_index(drop = True)\n",
    "\n",
    "    # extract top wrong preds per class\n",
    "    df_no = df_no.sort_values(['label', 'confidence'], ascending = False)\n",
    "    top_p = CFG['droop_noise'] if CFG['drop_noise'] else CFG['flip_noise']\n",
    "    df_no = df_no.groupby('label').apply(lambda x: x.head(int(len(x)*top_p))).reset_index(drop = True)\n",
    "    print('No. noisy images:', len(df_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cgwYKa_OkwFs"
   },
   "outputs": [],
   "source": [
    "####### DATASET\n",
    "\n",
    "class LeafData(Dataset):\n",
    "    \n",
    "    # initialization\n",
    "    def __init__(self, \n",
    "                 data, \n",
    "                 directory, \n",
    "                 transform    = None, \n",
    "                 labeled      = False,\n",
    "                 pairing      = False,\n",
    "                 pairing_prob = 0.01,\n",
    "                 pixel_crop   = 50,\n",
    "                 seed         = 0):\n",
    "        \n",
    "        self.data         = data\n",
    "        self.directory    = directory\n",
    "        self.transform    = transform\n",
    "        self.labeled      = labeled\n",
    "        self.pairing      = pairing\n",
    "        self.pairing_prob = pairing_prob\n",
    "        self.seed         = seed\n",
    "        self.counter      = 0\n",
    "        self.pixel_crop   = pixel_crop\n",
    "        if pairing:\n",
    "            self.sampled_idx = self.data.sample(frac=self.pairing_prob, random_state=self.seed).index\n",
    "        \n",
    "    # length\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    # get item  \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # import\n",
    "        path  = os.path.join(self.directory, self.data.iloc[idx]['image_id'])\n",
    "        image = cv2.imread(path)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "        # augmentations\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image = image)['image']\n",
    "            \n",
    "        if self.pairing:\n",
    "            if idx in self.sampled_idx:\n",
    "                \n",
    "                try:\n",
    "                    add_path     = os.path.join(self.directory, self.data.loc[self.data.label==self.data.iloc[idx]['label']].sample(1, random_state=self.seed)['image_id'].iloc[0])\n",
    "                except:\n",
    "                    print(self.data.sample(1, random_state=self.seed))\n",
    "                    add_path     = os.path.join(self.directory, self.data.sample(1, random_state=self.seed)['image_id'].iloc[0])\n",
    "                    self.counter += 1\n",
    "                    \n",
    "                add_image = cv2.imread(add_path)\n",
    "                add_image = cv2.cvtColor(add_image, cv2.COLOR_BGR2RGB)\n",
    "                if self.transform is not None:\n",
    "                    add_image = self.transform(image = add_image)['image']\n",
    "                    \n",
    "                max_x = add_image.shape[2] - self.pixel_crop\n",
    "                max_y = add_image.shape[1] - self.pixel_crop\n",
    "                \n",
    "                x = torch.randint(0, max_x, (1,))\n",
    "                y = torch.randint(0, max_y, (1,))\n",
    "                crop  = add_image[:, y: y + self.pixel_crop, x: x + self.pixel_crop]\n",
    "                image[:, y: y + self.pixel_crop, x: x + self.pixel_crop] = crop\n",
    "                \n",
    "        \n",
    "        # output\n",
    "        if self.labeled:\n",
    "            labels = torch.tensor(self.data.iloc[idx]['label']).long()\n",
    "            return image, labels\n",
    "        else:\n",
    "            return image\n",
    "        \n",
    "        def get_counter(self):\n",
    "            print(f'{self.counter} observations were cropped with the sample from another class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVog-f8UjJzC"
   },
   "source": [
    "# AUGMENTATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8WM5RZeLhH6d"
   },
   "outputs": [],
   "source": [
    "####### AUGMENTATIONS\n",
    "\n",
    "def get_augs(CFG, image_size = None, p_augment = None):\n",
    "\n",
    "    # update epoch-based parameters\n",
    "    if image_size is None:\n",
    "        image_size = CFG['image_size']\n",
    "    if p_augment is None:\n",
    "        p_augment = CFG['p_augment']\n",
    "\n",
    "    # normalization\n",
    "    if CFG['normalize']:\n",
    "        if CFG['normalize'] == 'dataset':\n",
    "            CFG['pixel_mean'] = (0.442, 0.511, 0.318)\n",
    "            CFG['pixels_std'] = (0.233, 0.236, 0.225)\n",
    "        elif CFG['normalize'] == 'imagenet':\n",
    "            CFG['pixel_mean'] = (0.485, 0.456, 0.406)\n",
    "            CFG['pixels_std'] = (0.229, 0.224, 0.225)\n",
    "    else:\n",
    "        CFG['pixel_mean'] = (0, 0, 0)\n",
    "        CFG['pixels_std'] = (1, 1, 1)\n",
    "\n",
    "    # train augmentations\n",
    "    train_augs = A.Compose([A.RandomResizedCrop(height = image_size, \n",
    "                                                width  = image_size,\n",
    "                                                scale  = CFG['crop_scale']),\n",
    "                            A.RandomGridShuffle(p    = p_augment,\n",
    "                                              grid = CFG['gr_shuffle']),\n",
    "                            A.Transpose(p = 0.5),\n",
    "                            A.HorizontalFlip(p = 0.5),\n",
    "                            A.VerticalFlip(p = 0.5),\n",
    "                            A.ShiftScaleRotate(p            = p_augment,\n",
    "                                               shift_limit  = CFG['ssr'][0],\n",
    "                                               scale_limit  = CFG['ssr'][1],\n",
    "                                               rotate_limit = CFG['ssr'][2]),\n",
    "                            A.HueSaturationValue(p               = p_augment,\n",
    "                                                 hue_shift_limit = CFG['huesat'][0],\n",
    "                                                 sat_shift_limit = CFG['huesat'][1],\n",
    "                                                 val_shift_limit = CFG['huesat'][2]),\n",
    "                            A.RandomBrightnessContrast(p                = p_augment,\n",
    "                                                       brightness_limit = CFG['bricon'][0],\n",
    "                                                       contrast_limit   = CFG['bricon'][1]),\n",
    "                            A.OneOf([A.MotionBlur(blur_limit   = CFG['blur_limit']),\n",
    "                                     A.MedianBlur(blur_limit   = CFG['blur_limit']),\n",
    "                                     A.GaussianBlur(blur_limit = CFG['blur_limit'])], \n",
    "                                     p = p_augment),\n",
    "                            A.OneOf([A.OpticalDistortion(distort_limit = CFG['dist_limit']),\n",
    "                                     A.GridDistortion(distort_limit    = CFG['dist_limit'])], \n",
    "                                     p = p_augment),\n",
    "                            A.Cutout(p          = p_augment, \n",
    "                                     num_holes  = CFG['cutout'][0], \n",
    "                                     max_h_size = np.int(CFG['cutout'][1] * image_size), \n",
    "                                     max_w_size = np.int(CFG['cutout'][1] * image_size)),\n",
    "                            A.Normalize(mean = CFG['pixel_mean'],\n",
    "                                        std  = CFG['pixels_std']),\n",
    "                            ToTensorV2()\n",
    "                           ])\n",
    "\n",
    "    # test augmentations\n",
    "    test_augs = A.Compose([A.SmallestMaxSize(max_size = image_size),\n",
    "                           A.CenterCrop(height = image_size, \n",
    "                                        width  = image_size),\n",
    "                           A.Normalize(mean = CFG['pixel_mean'],\n",
    "                                       std  = CFG['pixels_std']),\n",
    "                           ToTensorV2()\n",
    "                           ])\n",
    "    \n",
    "    # output\n",
    "    return train_augs, test_augs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ECgTVx9sjMud"
   },
   "outputs": [],
   "source": [
    "####### CUTMIX\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w   = np.int(W * cut_rat)\n",
    "    cut_h   = np.int(H * cut_rat)\n",
    "\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "\n",
    "def cutmix_fn(data, target, alpha):\n",
    "\n",
    "    indices         = torch.randperm(data.size(0))\n",
    "    shuffled_data   = data[indices]\n",
    "    shuffled_target = target[indices]\n",
    "\n",
    "    lam = np.clip(np.random.beta(alpha, alpha), 0.3, 0.4)\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(data.size(), lam)\n",
    "    new_data = data.clone()\n",
    "    new_data[:, :, bby1:bby2, bbx1:bbx2] = data[indices, :, bby1:bby2, bbx1:bbx2]\n",
    "\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (data.size()[-1] * data.size()[-2]))\n",
    "    targets = (target, shuffled_target, lam)\n",
    "\n",
    "    return new_data, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8P1MdMtPb4j"
   },
   "outputs": [],
   "source": [
    "####### TTA HELPER FUNCTION\n",
    "\n",
    "def get_tta_flips(img, i):\n",
    "\n",
    "    if i >= 4:\n",
    "        img = img.transpose(2, 3)\n",
    "    if i % 4 == 0:\n",
    "        return img\n",
    "    elif i % 4 == 1:\n",
    "        return img.flip(2)\n",
    "    elif i % 4 == 2:\n",
    "        return img.flip(3)\n",
    "    elif i % 4 == 3:\n",
    "        return img.flip(2).flip(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "xBXNJJBe3uw_",
    "outputId": "21268877-6803-427d-e339-7bb181dabb93"
   },
   "outputs": [],
   "source": [
    "####### EXAMINE SAMPLE BATCH\n",
    "\n",
    "# sample size\n",
    "sample = 5\n",
    "\n",
    "# augmentations\n",
    "train_augs, test_augs = get_augs(CFG, image_size = 128)\n",
    "\n",
    "# datasets\n",
    "train_dataset = LeafData(data         = df.head(sample*2), \n",
    "                         directory    = CFG['data_path'] + 'train_images/',\n",
    "                         transform    = train_augs,\n",
    "                         labeled      = True, \n",
    "                         pairing      = CFG['pairing'],\n",
    "                         pairing_prob = 0.3,\n",
    "                         seed         = CFG['seed'])\n",
    "test_dataset = LeafData(data       = df.head(sample*2), \n",
    "                        directory  = CFG['data_path'] + 'train_images/',\n",
    "                        transform  = test_augs,\n",
    "                        labeled    = True)\n",
    "\n",
    "# data loaders\n",
    "train_loader = DataLoader(dataset     = train_dataset, \n",
    "                          batch_size  = sample, \n",
    "                          shuffle       = False, \n",
    "                          num_workers = 0,\n",
    "                          pin_memory  = True)\n",
    "test_loader = DataLoader(dataset      = test_dataset, \n",
    "                         batch_size   = sample, \n",
    "                         shuffle        = False, \n",
    "                         num_workers  = 0,\n",
    "                         pin_memory   = True)\n",
    "\n",
    "# display train images\n",
    "batch_time = time.time()\n",
    "for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "\n",
    "    # apply cutmix augmentation\n",
    "    if CFG['cutmix'][0] > 0:\n",
    "        mix_decision = 0 #np.random.rand(1)\n",
    "        if mix_decision < CFG['cutmix'][0]:\n",
    "            inputs, _ = cutmix_fn(data   = inputs, \n",
    "                                  target = labels, \n",
    "                                  alpha  = cutmix[1])\n",
    "\n",
    "    # feedback\n",
    "    inputs_shape = inputs.shape\n",
    "    load_time    = time.time() - batch_time\n",
    "    pixel_values = [torch.min(inputs).item(), torch.mean(inputs).item(), torch.max(inputs).item()]\n",
    "\n",
    "    # examples\n",
    "    fig = plt.figure(figsize = (20, 8))\n",
    "    for i in range(sample):\n",
    "        ax = fig.add_subplot(2, sample, i + 1, xticks = [], yticks = [])     \n",
    "        plt.imshow(inputs[i].numpy().transpose(1, 2, 0))\n",
    "        ax.set_title('Label: {} [train]'.format(labels[i].numpy()), color = 'red')\n",
    "    break\n",
    "\n",
    "# display test images\n",
    "batch_time = time.time()\n",
    "for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "\n",
    "    # feedback\n",
    "    print('- batch shape:  {} vs {}'.format(inputs_shape, inputs.shape))\n",
    "    print('- loading time: {:.4f} vs {:.4f} seconds'.format(load_time, (time.time() - batch_time)))\n",
    "    print('- pixel values: {:.2f} - {:.2f} - {:.2f} vs {:.2f} - {:.2f} - {:.2f}'.format(\n",
    "        pixel_values[0], pixel_values[1], pixel_values[2],\n",
    "        torch.min(inputs).item(), torch.mean(inputs).item(), torch.max(inputs).item()))\n",
    "\n",
    "    # examples\n",
    "    for i in range(sample):\n",
    "        ax = fig.add_subplot(2, sample, sample + i + 1, xticks = [], yticks = [])     \n",
    "        plt.imshow(inputs[i].numpy().transpose(1, 2, 0))\n",
    "        ax.set_title('Label: {} [valid]'.format(labels[i].numpy()), color = 'green')\n",
    "    plt.savefig(CFG['out_path'] + 'fig_sample.png')\n",
    "    break\n",
    "    \n",
    "# clean up\n",
    "del inputs, labels, batch_idx, train_loader, test_loader, train_dataset, test_dataset, train_augs, test_augs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hy3yRPC0VjC"
   },
   "source": [
    "# MODEL PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gqlv8kQU0VjD"
   },
   "outputs": [],
   "source": [
    "####### MODEL ARCHITECTURE\n",
    "\n",
    "def init_model(CFG, device, path = None):\n",
    "\n",
    "    ##### CONVOLUTIONAL PART\n",
    "\n",
    "    if 'deit' in CFG['backbone']: \n",
    "        model = torch.hub.load(repo_or_dir = 'facebookresearch/deit:main', \n",
    "                               model       = CFG['backbone'], \n",
    "                               pretrained  = False if (CFG['weights'] == 'empty') or (CFG['weights'] == 'custom') else True)\n",
    "                 \n",
    "    else:\n",
    "        model = timm.create_model(model_name = CFG['backbone'], \n",
    "                                  pretrained = False if (CFG['weights'] == 'empty') or (CFG['weights'] == 'custom') else True)\n",
    "        \n",
    "\n",
    "    ##### CUSTOM WEIGHTS\n",
    "\n",
    "    if CFG['weights'] == 'custom':\n",
    "\n",
    "        if 'efficient' in CFG['backbone']:\n",
    "            model.classifier = nn.Linear(model.classifier.in_features, CFG['pr_num_classes'])\n",
    "        elif ('vit' in CFG['backbone']) or ('deit' in CFG['backbone']):\n",
    "            model.head = nn.Linear(model.head.in_features, CFG['pr_num_classes'])\n",
    "        else:\n",
    "            model.fc = nn.Linear(model.fc.in_features, CFG['pr_num_classes'])\n",
    "        \n",
    "        path = 'weights_tf_efficientnet_b4_ns_pretrain.pth'\n",
    "        path = 'weights_swsl_resnext50_32x4d_pretrain.pth'\n",
    "        model.load_state_dict(torch.load(CFG['model_path'] + path, map_location = device))\n",
    "\n",
    "        \n",
    "    ##### CLASSIFIER PART\n",
    "\n",
    "    if (CFG['weights'] != 'custom') or ((CFG['weights'] == 'custom') and (CFG['num_classes'] != CFG['pr_num_classes'])):\n",
    "    \n",
    "        if 'efficient' in CFG['backbone']:\n",
    "            model.classifier = nn.Linear(model.classifier.in_features, CFG['num_classes'])\n",
    "        elif ('vit' in CFG['backbone']) or ('deit' in CFG['backbone']):\n",
    "            model.head = nn.Linear(model.head.in_features, CFG['num_classes'])\n",
    "        else:\n",
    "            model.fc = nn.Linear(model.fc.in_features, CFG['num_classes'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6gRl0q0_9oUh"
   },
   "outputs": [],
   "source": [
    "####### MODEL INSPECTION\n",
    "\n",
    "model_inspection = False\n",
    "\n",
    "if model_inspection:\n",
    "\n",
    "    # libraries\n",
    "    !pip install torchsummary\n",
    "    from torchsummary import summary\n",
    "\n",
    "    # summary\n",
    "    model = init_model(CFG)\n",
    "    summary(model, (3, CFG['image_size'], CFG['image_size']))\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PVFoS1ezb7YQ"
   },
   "outputs": [],
   "source": [
    "####### LEARNING RATE FINDER\n",
    "\n",
    "lr_finder = False\n",
    "\n",
    "if lr_finder:\n",
    "\n",
    "    # libraries\n",
    "    !pip install torch-lr-finder\n",
    "    from torch_lr_finder import LRFinder\n",
    "    !pip install ipywidgets\n",
    "    from ipywidgets import IntProgress\n",
    "\n",
    "    # data loader\n",
    "    dataset = LeafData(data      = df, \n",
    "                       directory = CFG['data_path'] + 'train_images/',\n",
    "                       transform = train_augs,\n",
    "                       labeled   = True)\n",
    "    loader = DataLoader(dataset     = dataset, \n",
    "                        batch_size  = CFG['batch_size'], \n",
    "                        shuffle       = True, \n",
    "                        num_workers = CFG['num_workers'],\n",
    "                        pin_memory  = True)\n",
    "\n",
    "    # model and optimizer\n",
    "    model     = init_model(CFG)\n",
    "    model     = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 1e-8)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    # LR finder\n",
    "    lr_finder = LRFinder(model, optimizer, criterion, device)\n",
    "    lr_finder.range_test(loader, end_lr = 10, num_iter = 100)\n",
    "    lr_finder.plot() \n",
    "    lr_finder.reset()\n",
    "    \n",
    "    # cleanup\n",
    "    del dataset, loader, model, optimizer, criterion, lr_finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nEX8CKbgIpfp"
   },
   "outputs": [],
   "source": [
    "####### LOSS FUNCTIONS LIBRARY\n",
    "\n",
    "##### CROSSENTROPY WITH LABEL SMOOTHING\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "\n",
    "    def __init__(self, smoothing = 0.1, reduction = 'mean'):\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "        assert smoothing < 1.0\n",
    "        self.smoothing  = smoothing\n",
    "        self.confidence = 1. - smoothing\n",
    "        self.reduction  = reduction\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        logprobs = F.log_softmax(x, dim=-1)\n",
    "        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "        nll_loss = nll_loss.squeeze(1)\n",
    "        smooth_loss = -logprobs.mean(dim=-1)\n",
    "        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        return loss\n",
    "\n",
    "\n",
    "##### OHEM LOSS\n",
    "\n",
    "class OhemCrossEntropy(nn.Module):\n",
    "\n",
    "    def __init__(self, top_k = 0.7, smoothing = 0, reduction = 'none'):\n",
    "        super(OhemCrossEntropy, self).__init__()\n",
    "        self.reduction     = reduction\n",
    "        self.top_k         = top_k\n",
    "        self.smoothing     = smoothing\n",
    "        self.ce_lab_smooth = LabelSmoothingCrossEntropy(smoothing = self.smoothing, reduction = self.reduction)\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        log_probs = F.log_softmax(pred, dim=1)\n",
    "        loss      = self.ce_lab_smooth(log_probs, target)   \n",
    "        if self.top_k == 1:\n",
    "            return torch.mean(loss)\n",
    "        else:\n",
    "            valid_loss, idxs = torch.topk(loss, int(self.top_k * loss.size()[0]))    \n",
    "            return torch.mean(valid_loss)\n",
    "\n",
    "\n",
    "##### SYMMETRIC CROSSENTROPY\n",
    "\n",
    "class SymmetricCrossEntropy(nn.Module):\n",
    "\n",
    "    def __init__(self, alpha = 0.1, beta = 1.0, num_classes = 5, smoothing = 0, reduction = 'mean'):\n",
    "        super(SymmetricCrossEntropy, self).__init__()\n",
    "        self.alpha         = alpha\n",
    "        self.beta          = beta\n",
    "        self.num_classes   = num_classes\n",
    "        self.reduction     = reduction\n",
    "        self.smoothing     = smoothing\n",
    "        self.ce_lab_smooth = LabelSmoothingCrossEntropy(smoothing = self.smoothing, reduction = self.reduction)\n",
    "        \n",
    "    def forward(self, logits, targets):\n",
    "        onehot_targets = torch.eye(self.num_classes)[targets].to(device)\n",
    "        ce_loss  = self.ce_lab_smooth(logits, targets)\n",
    "        rce_loss = (-onehot_targets*logits.softmax(1).clamp(1e-7, 1.0).log()).sum(1)\n",
    "        if self.reduction == 'mean':\n",
    "            rce_loss = rce_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            rce_loss = rce_loss.sum()\n",
    "        return self.alpha * ce_loss + self.beta * rce_loss\n",
    "\n",
    "\n",
    "##### COMPLEMENT CROSSENTROPY\n",
    "\n",
    "class ComplementEntropy(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes = 5):\n",
    "        super(ComplementEntropy, self).__init__()\n",
    "        self.classes = num_classes\n",
    "        self.batch_size = None\n",
    "\n",
    "    def forward(self, y_hat, y):\n",
    "        self.batch_size = len(y)\n",
    "        y_hat = F.softmax(y_hat, dim=1)\n",
    "        Yg = torch.gather(y_hat, 1, torch.unsqueeze(y, 1))\n",
    "        Yg_ = (1 - Yg) + 1e-7\n",
    "        Px = y_hat / Yg_.view(len(y_hat), 1)\n",
    "        Px_log = torch.log(Px + 1e-10)\n",
    "        y_zerohot = torch.ones(self.batch_size, self.classes).scatter_\\\n",
    "            (1, y.view(self.batch_size, 1).data.cpu(), 0)\n",
    "        output = Px * Px_log * y_zerohot.to(device)\n",
    "        entropy = torch.sum(output)\n",
    "        entropy /= float(self.batch_size)\n",
    "        entropy /= float(self.classes)\n",
    "        return entropy\n",
    "\n",
    "class ComplementCrossEntropy(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes = 5, gamma = 5, smoothing = 0, reduction = 'mean'):\n",
    "        super(ComplementCrossEntropy, self).__init__()\n",
    "        self.gamma              = gamma\n",
    "        self.smoothing          = smoothing\n",
    "        self.reduction          = reduction\n",
    "        self.complement_entropy = ComplementEntropy(num_classes)\n",
    "        self.ce_lab_smooth      = LabelSmoothingCrossEntropy(smoothing = self.smoothing, reduction = self.reduction)\n",
    "\n",
    "    def forward(self, y_hat, y):\n",
    "        l1 = self.ce_lab_smooth(y_hat, y)\n",
    "        l2 = self.complement_entropy(y_hat, y)\n",
    "        return l1 + self.gamma * l2\n",
    "\n",
    "\n",
    "##### FOCAL LOSS\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha = 1, gamma = 2, smoothing = 0, reduction = 'mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha         = alpha\n",
    "        self.gamma         = gamma\n",
    "        self.reduction     = reduction\n",
    "        self.smoothing     = smoothing\n",
    "        self.ce_lab_smooth = LabelSmoothingCrossEntropy(smoothing = self.smoothing, reduction = self.reduction)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = self.ce_lab_smooth(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(F_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(F_loss)\n",
    "        return F_loss\n",
    "        \n",
    "\n",
    "##### FOCAL COSINE LOSS\n",
    "\n",
    "class FocalCosineLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, alpha = 1, gamma = 2, xent = 0.1, smoothing = 0, reduction = 'mean'):\n",
    "        super(FocalCosineLoss, self).__init__()\n",
    "        self.alpha         = alpha\n",
    "        self.gamma         = gamma\n",
    "        self.xent          = xent\n",
    "        self.y             = torch.Tensor([1]).to(device)\n",
    "        self.reduction     = reduction\n",
    "        self.smoothing     = smoothing\n",
    "        self.ce_lab_smooth = LabelSmoothingCrossEntropy(smoothing = self.smoothing, reduction = 'none')\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        cosine_loss = F.cosine_embedding_loss(input, F.one_hot(target, num_classes=input.size(-1)), self.y, reduction=self.reduction)\n",
    "        cent_loss   = self.ce_lab_smooth(F.normalize(input), target)\n",
    "        pt = torch.exp(-cent_loss)\n",
    "        focal_loss = self.alpha * (1-pt)**self.gamma * cent_loss\n",
    "        if self.reduction == \"mean\":\n",
    "            focal_loss = torch.mean(focal_loss)\n",
    "        elif self.reduction == \"sum\":\n",
    "            focal_loss = torch.mean(focal_loss)\n",
    "        return cosine_loss + self.xent * focal_loss\n",
    "  \n",
    "    \n",
    "##### TAYLOR LOSS\n",
    "\n",
    "class TaylorSoftmax(nn.Module):\n",
    "\n",
    "    def __init__(self, dim=1, n=2):\n",
    "        super(TaylorSoftmax, self).__init__()\n",
    "        assert n % 2 == 0\n",
    "        self.dim = dim\n",
    "        self.n = n\n",
    "\n",
    "    def forward(self, x):\n",
    "        fn = torch.ones_like(x)\n",
    "        denor = 1.\n",
    "        for i in range(1, self.n+1):\n",
    "            denor *= i\n",
    "            fn = fn + x.pow(i) / denor\n",
    "        out = fn / fn.sum(dim=self.dim, keepdims=True)\n",
    "        return out\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1): \n",
    "        super(LabelSmoothingLoss, self).__init__() \n",
    "        self.confidence = 1.0 - smoothing \n",
    "        self.smoothing = smoothing \n",
    "        self.cls       = classes \n",
    "        self.dim       = dim \n",
    "\n",
    "    def forward(self, pred, target): \n",
    "        with torch.no_grad(): \n",
    "            true_dist = torch.zeros_like(pred) \n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1)) \n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence) \n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))\n",
    "\n",
    "class TaylorCrossEntropyLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, n = 2, ignore_index = -1, reduction = 'mean', smoothing = 0):\n",
    "        super(TaylorCrossEntropyLoss, self).__init__()\n",
    "        assert n % 2 == 0\n",
    "        self.taylor_softmax = TaylorSoftmax(dim=1, n=n)\n",
    "        self.reduction      = reduction\n",
    "        self.ignore_index   = ignore_index\n",
    "        self.lab_smooth     = LabelSmoothingLoss(CFG['num_classes'], smoothing = smoothing)\n",
    "        self.smoothing      = smoothing\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        log_probs = self.taylor_softmax(logits).log()\n",
    "        if self.smoothing == 0:\n",
    "            loss = F.nll_loss(log_probs, labels, reduction=self.reduction,\n",
    "                    ignore_index=self.ignore_index)\n",
    "        else:\n",
    "            loss = self.lab_smooth(log_probs, labels)\n",
    "        return loss\n",
    "       \n",
    "    \n",
    "##### BI-TEMPERED LOSS\n",
    "\n",
    "def log_t(u, t):\n",
    "    if t==1.0:\n",
    "        return u.log()\n",
    "    else:\n",
    "        return (u.pow(1.0 - t) - 1.0) / (1.0 - t)\n",
    "\n",
    "def exp_t(u, t):\n",
    "    if t==1:\n",
    "        return u.exp()\n",
    "    else:\n",
    "        return (1.0 + (1.0-t)*u).relu().pow(1.0 / (1.0 - t))\n",
    "\n",
    "def compute_normalization_fixed_point(activations, t, num_iters):\n",
    "    mu, _ = torch.max(activations, -1, keepdim=True)\n",
    "    normalized_activations_step_0 = activations - mu\n",
    "\n",
    "    normalized_activations = normalized_activations_step_0\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        logt_partition = torch.sum(\n",
    "                exp_t(normalized_activations, t), -1, keepdim=True)\n",
    "        normalized_activations = normalized_activations_step_0 * \\\n",
    "                logt_partition.pow(1.0-t)\n",
    "\n",
    "    logt_partition = torch.sum(\n",
    "            exp_t(normalized_activations, t), -1, keepdim=True)\n",
    "    normalization_constants = - log_t(1.0 / logt_partition, t) + mu\n",
    "\n",
    "    return normalization_constants\n",
    "\n",
    "def compute_normalization_binary_search(activations, t, num_iters):\n",
    "    mu, _ = torch.max(activations, -1, keepdim=True)\n",
    "    normalized_activations = activations - mu\n",
    "\n",
    "    effective_dim = \\\n",
    "        torch.sum(\n",
    "                (normalized_activations > -1.0 / (1.0-t)).to(torch.int32),\n",
    "            dim=-1, keepdim=True).to(activations.dtype)\n",
    "\n",
    "    shape_partition = activations.shape[:-1] + (1,)\n",
    "    lower = torch.zeros(shape_partition, dtype=activations.dtype, device=activations.device)\n",
    "    upper = -log_t(1.0/effective_dim, t) * torch.ones_like(lower)\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        logt_partition = (upper + lower)/2.0\n",
    "        sum_probs = torch.sum(\n",
    "                exp_t(normalized_activations - logt_partition, t),\n",
    "                dim=-1, keepdim=True)\n",
    "        update = (sum_probs < 1.0).to(activations.dtype)\n",
    "        lower = torch.reshape(\n",
    "                lower * update + (1.0-update) * logt_partition,\n",
    "                shape_partition)\n",
    "        upper = torch.reshape(\n",
    "                upper * (1.0 - update) + update * logt_partition,\n",
    "                shape_partition)\n",
    "\n",
    "    logt_partition = (upper + lower)/2.0\n",
    "    return logt_partition + mu\n",
    "\n",
    "class ComputeNormalization(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, activations, t, num_iters):\n",
    "        if t < 1.0:\n",
    "            normalization_constants = compute_normalization_binary_search(activations, t, num_iters)\n",
    "        else:\n",
    "            normalization_constants = compute_normalization_fixed_point(activations, t, num_iters)\n",
    "\n",
    "        ctx.save_for_backward(activations, normalization_constants)\n",
    "        ctx.t=t\n",
    "        return normalization_constants\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        activations, normalization_constants = ctx.saved_tensors\n",
    "        t = ctx.t\n",
    "        normalized_activations = activations - normalization_constants \n",
    "        probabilities = exp_t(normalized_activations, t)\n",
    "        escorts = probabilities.pow(t)\n",
    "        escorts = escorts / escorts.sum(dim=-1, keepdim=True)\n",
    "        grad_input = escorts * grad_output\n",
    "        \n",
    "        return grad_input, None, None\n",
    "\n",
    "def compute_normalization(activations, t, num_iters=5):\n",
    "    return ComputeNormalization.apply(activations, t, num_iters)\n",
    "\n",
    "def tempered_sigmoid(activations, t, num_iters = 5):\n",
    "    internal_activations = torch.stack([activations,\n",
    "        torch.zeros_like(activations)],\n",
    "        dim=-1)\n",
    "    internal_probabilities = tempered_softmax(internal_activations, t, num_iters)\n",
    "    return internal_probabilities[..., 0]\n",
    "\n",
    "\n",
    "def tempered_softmax(activations, t, num_iters=5):\n",
    "    if t == 1.0:\n",
    "        return activations.softmax(dim=-1)\n",
    "\n",
    "    normalization_constants = compute_normalization(activations, t, num_iters)\n",
    "    return exp_t(activations - normalization_constants, t)\n",
    "\n",
    "def bi_tempered_binary_logistic_loss(activations,\n",
    "        labels,\n",
    "        t1,\n",
    "        t2,\n",
    "        label_smoothing = 0.0,\n",
    "        num_iters=5,\n",
    "        reduction='mean'):\n",
    "\n",
    "    internal_activations = torch.stack([activations,\n",
    "        torch.zeros_like(activations)],\n",
    "        dim=-1)\n",
    "    internal_labels = torch.stack([labels.to(activations.dtype),\n",
    "        1.0 - labels.to(activations.dtype)],\n",
    "        dim=-1)\n",
    "    return bi_tempered_logistic_loss(internal_activations, \n",
    "            internal_labels,\n",
    "            t1,\n",
    "            t2,\n",
    "            label_smoothing = label_smoothing,\n",
    "            num_iters = num_iters,\n",
    "            reduction = reduction)\n",
    "\n",
    "def bi_tempered_logistic_loss(activations,\n",
    "        labels,\n",
    "        t1,\n",
    "        t2,\n",
    "        label_smoothing=0.0,\n",
    "        num_iters=5,\n",
    "        reduction = 'mean'):\n",
    "\n",
    "    if len(labels.shape)<len(activations.shape): #not one-hot\n",
    "        labels_onehot = torch.zeros_like(activations)\n",
    "        labels_onehot.scatter_(1, labels[..., None], 1)\n",
    "    else:\n",
    "        labels_onehot = labels\n",
    "\n",
    "    if label_smoothing > 0:\n",
    "        num_classes = labels_onehot.shape[-1]\n",
    "        labels_onehot = ( 1 - label_smoothing * num_classes / (num_classes - 1) ) \\\n",
    "                * labels_onehot + \\\n",
    "                label_smoothing / (num_classes - 1)\n",
    "\n",
    "    probabilities = tempered_softmax(activations, t2, num_iters)\n",
    "\n",
    "    loss_values = labels_onehot * log_t(labels_onehot + 1e-10, t1) \\\n",
    "            - labels_onehot * log_t(probabilities, t1) \\\n",
    "            - labels_onehot.pow(2.0 - t1) / (2.0 - t1) \\\n",
    "            + probabilities.pow(2.0 - t1) / (2.0 - t1)\n",
    "    loss_values = loss_values.sum(dim = -1) #sum over classes\n",
    "\n",
    "    if reduction == 'none':\n",
    "        return loss_values\n",
    "    if reduction == 'sum':\n",
    "        return loss_values.sum()\n",
    "    if reduction == 'mean':\n",
    "        return loss_values.mean()\n",
    "\n",
    "class BiTemperedLogisticLoss(nn.Module): \n",
    "    def __init__(self, t1, t2, smoothing=0.0): \n",
    "        super(BiTemperedLogisticLoss, self).__init__() \n",
    "        self.t1 = t1\n",
    "        self.t2 = t2\n",
    "        self.smoothing = smoothing\n",
    "    def forward(self, logit_label, truth_label):\n",
    "        loss_label = bi_tempered_logistic_loss(\n",
    "            logit_label, truth_label,\n",
    "            t1=self.t1, t2=self.t2,\n",
    "            label_smoothing=self.smoothing,\n",
    "            reduction='none'\n",
    "        )\n",
    "        \n",
    "        loss_label = loss_label.mean()\n",
    "        return loss_label\n",
    "\n",
    "\n",
    "##### ISDA LOSS\n",
    "\n",
    "class EstimatorCV():\n",
    "    \n",
    "    def __init__(self, feature_num, class_num):\n",
    "        super(EstimatorCV, self).__init__()\n",
    "        self.class_num = class_num\n",
    "        self.CoVariance = torch.zeros(class_num, feature_num, feature_num).to(device)\n",
    "        self.Ave = torch.zeros(class_num, feature_num).to(device)\n",
    "        self.Amount = torch.zeros(class_num).to(device)\n",
    "\n",
    "    def update_CV(self, features, labels):\n",
    "        N = features.size(0)\n",
    "        C = self.class_num\n",
    "        A = features.size(1)\n",
    "        NxCxFeatures = features.view(\n",
    "            N, 1, A\n",
    "        ).expand(\n",
    "            N, C, A\n",
    "        )\n",
    "        onehot = torch.zeros(N, C).to(device)\n",
    "        onehot.scatter_(1, labels.view(-1, 1), 1)\n",
    "        NxCxA_onehot = onehot.view(N, C, 1).expand(N, C, A)\n",
    "        features_by_sort = NxCxFeatures.mul(NxCxA_onehot)\n",
    "        Amount_CxA = NxCxA_onehot.sum(0)\n",
    "        Amount_CxA[Amount_CxA == 0] = 1\n",
    "        ave_CxA = features_by_sort.sum(0) / Amount_CxA\n",
    "        var_temp = features_by_sort - \\\n",
    "                   ave_CxA.expand(N, C, A).mul(NxCxA_onehot)\n",
    "        var_temp = torch.bmm(\n",
    "            var_temp.permute(1, 2, 0),\n",
    "            var_temp.permute(1, 0, 2)\n",
    "        ).div(Amount_CxA.view(C, A, 1).expand(C, A, A))\n",
    "        sum_weight_CV = onehot.sum(0).view(C, 1, 1).expand(C, A, A)\n",
    "        sum_weight_AV = onehot.sum(0).view(C, 1).expand(C, A)\n",
    "        weight_CV = sum_weight_CV.div(\n",
    "            sum_weight_CV + self.Amount.view(C, 1, 1).expand(C, A, A)\n",
    "        )\n",
    "        weight_CV[weight_CV != weight_CV] = 0\n",
    "        weight_AV = sum_weight_AV.div(\n",
    "            sum_weight_AV + self.Amount.view(C, 1).expand(C, A)\n",
    "        )\n",
    "        weight_AV[weight_AV != weight_AV] = 0\n",
    "        additional_CV = weight_CV.mul(1 - weight_CV).mul(\n",
    "            torch.bmm(\n",
    "                (self.Ave - ave_CxA).view(C, A, 1),\n",
    "                (self.Ave - ave_CxA).view(C, 1, A)\n",
    "            )\n",
    "        )\n",
    "        self.CoVariance = (self.CoVariance.mul(1 - weight_CV) + var_temp\n",
    "                      .mul(weight_CV)).detach() + additional_CV.detach()\n",
    "        self.Ave = (self.Ave.mul(1 - weight_AV) + ave_CxA.mul(weight_AV)).detach()\n",
    "        self.Amount += onehot.sum(0)\n",
    "\n",
    "\n",
    "class ISDALoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, feature_num, class_num, smoothing):\n",
    "        super(ISDALoss, self).__init__()\n",
    "        self.estimator = EstimatorCV(feature_num, class_num)\n",
    "        self.class_num = class_num\n",
    "        self.cross_entropy = nn.LabelSmoothingCrossEntropy(smoothing = smoothing)\n",
    "\n",
    "    def isda_aug(self, fc, features, y, labels, cv_matrix, ratio):\n",
    "        N = features.size(0)\n",
    "        C = self.class_num\n",
    "        A = features.size(1)\n",
    "        weight_m = list(fc.parameters())[0]\n",
    "        NxW_ij = weight_m.expand(N, C, A)\n",
    "        NxW_kj = torch.gather(NxW_ij,\n",
    "                              1,\n",
    "                              labels.view(N, 1, 1)\n",
    "                              .expand(N, C, A))\n",
    "        CV_temp = cv_matrix[labels]\n",
    "        sigma2 = ratio * \\\n",
    "                 torch.bmm(torch.bmm(NxW_ij - NxW_kj,\n",
    "                                     CV_temp),\n",
    "                           (NxW_ij - NxW_kj).permute(0, 2, 1))\n",
    "        sigma2 = sigma2.mul(torch.eye(C).to(device)\n",
    "                            .expand(N, C, C)).sum(2).view(N, C)\n",
    "        aug_result = y + 0.5 * sigma2\n",
    "        return aug_result\n",
    "\n",
    "    def forward(self, model, fc, x, target_x, ratio):\n",
    "        features = model(x)\n",
    "        y = fc(features)\n",
    "        self.estimator.update_CV(features.detach(), target_x)\n",
    "        isda_aug_y = self.isda_aug(fc, features, y, target_x, self.estimator.CoVariance.detach(), ratio)\n",
    "        loss = self.cross_entropy(isda_aug_y, target_x)\n",
    "        return loss, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OHm1Ky0In_6-"
   },
   "outputs": [],
   "source": [
    "####### GRADCAM MODULES\n",
    "\n",
    "class FeatureExtractor():\n",
    "    \"\"\" Class for extracting activations and\n",
    "    registering gradients from targetted intermediate layers \"\"\"\n",
    "\n",
    "    def __init__(self, model, target_layers):\n",
    "        self.model = model\n",
    "        self.target_layers = target_layers\n",
    "        self.gradients = []\n",
    "\n",
    "    def save_gradient(self, grad):\n",
    "        self.gradients.append(grad)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        outputs = []\n",
    "        self.gradients = []\n",
    "        for name, module in self.model._modules.items():\n",
    "            x = module(x)\n",
    "            if name in self.target_layers:\n",
    "                x.register_hook(self.save_gradient)\n",
    "                outputs += [x]\n",
    "        return outputs, x\n",
    "\n",
    "\n",
    "class ModelOutputs():\n",
    "    \"\"\" Class for making a forward pass, and getting:\n",
    "    1. The network output.\n",
    "    2. Activations from intermeddiate targetted layers.\n",
    "    3. Gradients from intermeddiate targetted layers. \"\"\"\n",
    "\n",
    "    def __init__(self, model, feature_module, target_layers):\n",
    "        self.model = model\n",
    "        self.feature_module = feature_module\n",
    "        self.feature_extractor = FeatureExtractor(self.feature_module, target_layers)\n",
    "\n",
    "    def get_gradients(self):\n",
    "        return self.feature_extractor.gradients\n",
    "\n",
    "    def __call__(self, x):\n",
    "        target_activations = []\n",
    "        for name, module in self.model._modules.items():\n",
    "            if module == self.feature_module:\n",
    "                target_activations, x = self.feature_extractor(x)\n",
    "            elif \"avgpool\" in name.lower():\n",
    "                x = module(x)\n",
    "                x = x.view(x.size(0),-1)\n",
    "            else:\n",
    "                x = module(x)\n",
    "\n",
    "        return target_activations, x\n",
    "\n",
    "\n",
    "class GradCam():\n",
    "\n",
    "    def __init__(self, model, feature_module, target_layer_names, use_cuda):\n",
    "        self.model = model\n",
    "        self.feature_module = feature_module\n",
    "        self.model.eval()\n",
    "        self.cuda = use_cuda\n",
    "        if self.cuda:\n",
    "            self.model = model.cuda()\n",
    "        self.extractor = ModelOutputs(self.model, self.feature_module, target_layer_names)\n",
    "\n",
    "    def forward(self, input_img):\n",
    "        return self.model(input_img)\n",
    "\n",
    "    def __call__(self, input_img, target_category=None):\n",
    "        if self.cuda:\n",
    "            input_img = input_img.cuda()\n",
    "\n",
    "        features, output = self.extractor(input_img)\n",
    "\n",
    "        if target_category == None:\n",
    "            target_category = np.argmax(output.cpu().data.numpy())\n",
    "\n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "        one_hot[0][target_category] = 1\n",
    "        one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
    "        if self.cuda:\n",
    "            one_hot = one_hot.cuda()\n",
    "        \n",
    "        one_hot = torch.sum(one_hot * output)\n",
    "\n",
    "        self.feature_module.zero_grad()\n",
    "        self.model.zero_grad()\n",
    "        one_hot.backward(retain_graph=True)\n",
    "\n",
    "        grads_val = self.extractor.get_gradients()[-1].cpu().data.numpy()\n",
    "\n",
    "        target = features[-1]\n",
    "        target = target.cpu().data.numpy()[0, :]\n",
    "\n",
    "        weights = np.mean(grads_val, axis = (2, 3))[0, :]\n",
    "        cam = np.zeros(target.shape[1:], dtype=np.float32)\n",
    "\n",
    "        for i, w in enumerate(weights):\n",
    "            cam += w * target[i, :, :]\n",
    "\n",
    "        cam = np.maximum(cam, 0)\n",
    "        cam = cv2.resize(cam, input_img.shape[2:])\n",
    "        cam = cam - np.min(cam)\n",
    "        cam = cam / np.max(cam)\n",
    "        return cam\n",
    "\n",
    "\n",
    "def show_cam_on_image(img, mask):\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * (1 - mask)), cv2.COLORMAP_JET)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "    cam = np.float32(img) + 0.5 * heatmap\n",
    "    cam = cam / np.max(cam)\n",
    "    return np.uint8(255 * cam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVfS9wOWAouA"
   },
   "source": [
    "# MAIN FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rRFagALUBXDX"
   },
   "outputs": [],
   "source": [
    "####### DATA PREP\n",
    "\n",
    "def get_data(df, fold, CFG, epoch = None):\n",
    "\n",
    "    ##### EPOCH-BASED PARAMS\n",
    "\n",
    "    # image size\n",
    "    if (CFG['step_size']) and (epoch is not None):\n",
    "        image_size = int(CFG['image_size'] * CFG['step_size'][epoch])\n",
    "    else:\n",
    "        image_size = CFG['image_size']\n",
    "\n",
    "    # no. classes\n",
    "    if (CFG['step_class']) and (epoch is not None):\n",
    "        num_classes = CFG['step_class'][epoch]\n",
    "    else:\n",
    "        num_classes = CFG['num_classes']\n",
    "\n",
    "    # augmentation probability\n",
    "    if (CFG['step_p_aug']) and (epoch is not None):\n",
    "        p_augment = CFG['p_augment'] * CFG['step_p_aug'][epoch]\n",
    "    else:\n",
    "        p_augment = CFG['p_augment']\n",
    "\n",
    "\n",
    "    ##### PARTITIONING\n",
    "\n",
    "    # load splits\n",
    "    df_train = df.loc[df.fold != fold].reset_index(drop = True)\n",
    "    df_valid = df.loc[df.fold == fold].reset_index(drop = True)     \n",
    "    if epoch is None:  \n",
    "        smart_print('-- no. images: train - {}, valid - {}'.format(len(df_train), len(df_valid)), CFG)\n",
    "\n",
    "    # 2019 labeled data\n",
    "    if CFG['data_2019']:\n",
    "        df_train = pd.concat([df_train, df_2019], axis = 0).reset_index(drop = True)\n",
    "        if epoch is None:  \n",
    "            smart_print('- appending 2019 labeled data to train...', CFG)\n",
    "            smart_print('-- no. images: train - {}, valid - {}'.format(len(df_train), len(df_valid)), CFG)\n",
    "\n",
    "    # 2019 psueudo-labeled data\n",
    "    if CFG['data_pl']:\n",
    "        df_train = pd.concat([df_train, df_pl], axis = 0).reset_index(drop = True)\n",
    "        if epoch is None:  \n",
    "            smart_print('- appending 2019 pseudo-labeled data to train...', CFG)\n",
    "            smart_print('-- no. images: train - {}, valid - {}'.format(len(df_train), len(df_valid)), CFG)\n",
    "\n",
    "    # external data\n",
    "    if CFG['data_ext']:\n",
    "        df_train = pd.concat([df_train, df_ext], axis = 0).reset_index(drop = True)\n",
    "        if epoch is None:  \n",
    "            smart_print('- appending external data to train...', CFG)\n",
    "            smart_print('-- no. images: train - {}, valid - {}'.format(len(df_train), len(df_valid)), CFG)\n",
    "\n",
    "\n",
    "    ##### SUBSETTING\n",
    "\n",
    "    # removing bad examples\n",
    "    if CFG['drop_dupl']:\n",
    "        df_train = df_train.loc[~df_train.image_id.isin(list_dupl)].reset_index(drop = True)\n",
    "    if CFG['drop_outs']:\n",
    "        df_train = df_train.loc[~df_train.image_id.isin(list_outs)].reset_index(drop = True)\n",
    "    if CFG['drop_noise']:\n",
    "        list_noise = list(df_no['image_id'].values)\n",
    "        df_train   = df_train.loc[~df_train.image_id.isin(list_noise)].reset_index(drop = True)\n",
    "    if CFG['flip_noise']:\n",
    "        list_noise = [img for img in df_no['image_id'].values if img in df_train['image_id'].values]\n",
    "        for img in list_noise:\n",
    "            df_train.loc[df_train.image_id == img, 'label'] = df_no.loc[df_no.image_id == img, 'pred'].astype('int').values\n",
    "    if epoch is None:  \n",
    "        smart_print('- dealing with bad images from train...', CFG)\n",
    "        smart_print('-- no. images: train - {}, valid - {}'.format(len(df_train), len(df_valid)), CFG)\n",
    "\n",
    "    # subset for debug mode\n",
    "    if CFG['debug']:\n",
    "        df_train = df_train.sample(CFG['batch_size'] * 5, random_state = CFG['seed']).reset_index(drop = True)\n",
    "        df_valid = df_valid.sample(CFG['batch_size'] * 5, random_state = CFG['seed']).reset_index(drop = True)\n",
    "\n",
    "\n",
    "    ##### DATASETS\n",
    "    \n",
    "    # target transformation\n",
    "    if num_classes == 2:\n",
    "        mapping = {'0': 0, '1': 0, '2': 0, '3': 0, '4': 1}\n",
    "        df_train['label'] = df_train['label'].map(mapping) \n",
    "        df_valid['label'] = df_valid['label'].map(mapping) \n",
    "        \n",
    "    # augmentations\n",
    "    train_augs, test_augs = get_augs(CFG, image_size, p_augment)\n",
    "\n",
    "    # datasets\n",
    "    train_dataset = LeafData(data         = df_train, \n",
    "                             directory    = CFG['data_path'] + 'train_images/',\n",
    "                             transform    = train_augs,\n",
    "                             labeled      = True,\n",
    "                             seed         = CFG['seed'],\n",
    "                             pairing      = CFG['pairing'],\n",
    "                             pixel_crop   = CFG['pixel_crop'],\n",
    "                             pairing_prob = CFG['pairing_prob'])\n",
    "    \n",
    "    valid_dataset = LeafData(data      = df_valid, \n",
    "                             directory = CFG['data_path'] + 'train_images/',\n",
    "                             transform = test_augs,\n",
    "                             labeled   = True)\n",
    "    \n",
    "    \n",
    "    ##### DATA SAMPLERS\n",
    "    \n",
    "    ### GPU SAMPLERS\n",
    "    if CFG['device'] != 'TPU':\n",
    "    \n",
    "        # samplers with oversampling \n",
    "        if CFG['oversample']:\n",
    "            weights        = 1. / torch.tensor(df_train['label'].value_counts(sort = False).values, dtype = torch.float)\n",
    "            sample_weights = weights[df_train['label']]\n",
    "            train_sampler  = WeightedRandomSampler(weights     = sample_weights,\n",
    "                                                   num_samples = len(sample_weights),\n",
    "                                                   replacement = True)\n",
    "            valid_sampler = SequentialSampler(valid_dataset)\n",
    "\n",
    "        # ordinary samplers\n",
    "        else:\n",
    "            train_sampler = RandomSampler(train_dataset)\n",
    "            valid_sampler = SequentialSampler(valid_dataset)\n",
    "        \n",
    "    ### TPU SAMPLERS  \n",
    "    if CFG['device'] == 'TPU':\n",
    "        \n",
    "        # distributed samplers\n",
    "        train_sampler = DistributedSampler(train_dataset,\n",
    "                                           num_replicas = xm.xrt_world_size(),\n",
    "                                           rank         = xm.get_ordinal(),\n",
    "                                           shuffle        = True)\n",
    "        valid_sampler = DistributedSampler(valid_dataset,\n",
    "                                           num_replicas = xm.xrt_world_size(),\n",
    "                                           rank         = xm.get_ordinal(),\n",
    "                                           shuffle        = False)\n",
    "        \n",
    "    ##### DATA LOADERS\n",
    "       \n",
    "    # data loaders\n",
    "    train_loader = DataLoader(dataset     = train_dataset, \n",
    "                              batch_size  = CFG['batch_size'], \n",
    "                              sampler     = train_sampler,\n",
    "                              num_workers = CFG['num_workers'],\n",
    "                              pin_memory  = True)\n",
    "    valid_loader = DataLoader(dataset     = valid_dataset, \n",
    "                              batch_size  = CFG['batch_size'], \n",
    "                              sampler     = valid_sampler, \n",
    "                              num_workers = CFG['num_workers'],\n",
    "                              pin_memory  = True)\n",
    "    \n",
    "    # feedback\n",
    "    if epoch is None:\n",
    "        smart_print('-' * 55, CFG)\n",
    "    smart_print('-- size: {}x{}, classes: {}, p(augment): {}'.format(image_size, image_size, num_classes, p_augment), CFG)\n",
    "\n",
    "    # output\n",
    "    return train_loader, valid_loader, df_train, df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aBlvl9A_18Uq"
   },
   "outputs": [],
   "source": [
    "####### LOSS PREP\n",
    "\n",
    "def get_losses(CFG, device, epoch = None):\n",
    "\n",
    "    # look up training loss\n",
    "    if CFG['step_loss'] and epoch is not None:\n",
    "        loss_fn = CFG['step_loss'][epoch]\n",
    "    else:\n",
    "        loss_fn = CFG['loss_fn']\n",
    "\n",
    "    # define training loss\n",
    "    if loss_fn == 'CE':\n",
    "        trn_criterion = LabelSmoothingCrossEntropy(smoothing = CFG['smoothing']).to(device)\n",
    "\n",
    "    elif loss_fn == 'OHEM':\n",
    "        trn_criterion = OhemCrossEntropy(top_k     = CFG['ohem'], \n",
    "                                         smoothing = CFG['smoothing']).to(device)\n",
    "\n",
    "    elif loss_fn == 'SCE':\n",
    "        trn_criterion = SymmetricCrossEntropy(alpha       = CFG['sce'][0],\n",
    "                                              beta        = CFG['sce'][1],\n",
    "                                              num_classes = CFG['num_classes'],\n",
    "                                              smoothing   = CFG['smoothing']).to(device)\n",
    "\n",
    "    elif loss_fn == 'CCE':\n",
    "        trn_criterion = ComplementCrossEntropy(gamma       = CFG['cce'],\n",
    "                                               num_classes = CFG['num_classes'],\n",
    "                                               smoothing   = CFG['smoothing']).to(device)\n",
    "\n",
    "    elif loss_fn == 'Focal':\n",
    "        trn_criterion = FocalLoss(alpha     = CFG['focal'][0],\n",
    "                                  gamma     = CFG['focal'][1],\n",
    "                                  smoothing = CFG['smoothing']).to(device)\n",
    "\n",
    "    elif loss_fn == 'FocalCosine':\n",
    "        trn_criterion = FocalCosineLoss(alpha     = CFG['focalcosine'][0],\n",
    "                                        gamma     = CFG['focalcosine'][1],\n",
    "                                        xent      = CFG['focalcosine'][2],\n",
    "                                        smoothing = CFG['smoothing']).to(device)\n",
    "\n",
    "    elif loss_fn == 'Taylor':\n",
    "        trn_criterion = TaylorCrossEntropyLoss(n         = CFG['taylor'], \n",
    "                                               smoothing = CFG['smoothing']).to(device)\n",
    "\n",
    "    elif loss_fn == 'BiTempered':\n",
    "        trn_criterion = BiTemperedLogisticLoss(t1        = CFG['bitempered'][0], \n",
    "                                               t2        = CFG['bitempered'][1], \n",
    "                                               smoothing = CFG['smoothing'])\n",
    "\n",
    "\n",
    "    # define validation loss\n",
    "    val_criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    # output\n",
    "    return trn_criterion, val_criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uel-01p5RBG8"
   },
   "outputs": [],
   "source": [
    "####### MODEL PREP\n",
    "\n",
    "def get_model(CFG, device, epoch = None):\n",
    "\n",
    "    ##### MODEL\n",
    "\n",
    "    # initialize model\n",
    "    model = init_model(CFG, device)\n",
    "\n",
    "    # send to device\n",
    "    if CFG['device'] != 'TPU':\n",
    "        model = model.to(device)\n",
    "    else:\n",
    "        mx    = xmp.MpModelWrapper(model)\n",
    "        model = mx.to(device)\n",
    "\n",
    "    # freezing deep layers\n",
    "    if epoch is not None:\n",
    "        if (CFG['fine_tune']) and (epoch >= CFG['num_epochs']):\n",
    "            for name, child in model.named_children():\n",
    "                if name not in ['classifier', 'fc', 'head']:\n",
    "                    for param in child.parameters():\n",
    "                        param.requires_grad = False\n",
    "            eta = CFG['eta_min']\n",
    "\n",
    "\n",
    "    ##### OPTIMIZER\n",
    "\n",
    "    # scale learning rates\n",
    "    if CFG['device'] == 'TPU':\n",
    "        eta     = CFG['eta']     * xm.xrt_world_size()\n",
    "        eta_min = CFG['eta_min'] * xm.xrt_world_size()\n",
    "    else:\n",
    "        eta     = CFG['eta']\n",
    "        eta_min = CFG['eta_min']\n",
    "\n",
    "    # optimizer\n",
    "    if CFG['optim'] == 'Adam':\n",
    "        optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr = eta, weight_decay = CFG['decay'])\n",
    "    elif CFG['optim'] == 'AdamW':\n",
    "        optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr = eta, weight_decay = CFG['decay'])\n",
    "    elif CFG['optim'] == 'AdamP':\n",
    "        optimizer = AdamP(filter(lambda p: p.requires_grad, model.parameters()), lr = eta, weight_decay = CFG['decay'])\n",
    "\n",
    "\n",
    "    ##### SCHEDULER\n",
    "\n",
    "    # after scheduler\n",
    "    if CFG['schedule'] == 'CosineAnnealing':\n",
    "        after_scheduler = CosineAnnealingWarmRestarts(optimizer = optimizer,\n",
    "                                                      T_0       = CFG['num_epochs'] - CFG['warmup'] if CFG['num_epochs'] > 1 else 1,\n",
    "                                                      eta_min   = eta_min)\n",
    "        \n",
    "    # warmup\n",
    "    scheduler = GradualWarmupScheduler(optimizer       = optimizer, \n",
    "                                       multiplier      = 1, \n",
    "                                       total_epoch     = CFG['warmup'] + 1, \n",
    "                                       after_scheduler = after_scheduler)\n",
    "\n",
    "    # output\n",
    "    return model, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zn1_xBjEBdAF"
   },
   "outputs": [],
   "source": [
    "####### TRAINING\n",
    "\n",
    "def train_epoch(loader, model, optimizer, scheduler, criterion, epoch, CFG, device):\n",
    "       \n",
    "    # switch regime\n",
    "    model.train()\n",
    "\n",
    "    # running loss\n",
    "    trn_loss = AverageMeter()\n",
    "\n",
    "    # update scheduler on epoch\n",
    "    if not CFG['update_on_batch']:\n",
    "        scheduler.step() \n",
    "        if epoch == CFG['warmup']:\n",
    "            scheduler.step() \n",
    "\n",
    "    # loop through batches\n",
    "    for batch_idx, (inputs, labels) in (tqdm(enumerate(loader), total = len(loader)) if CFG['device'] != 'TPU' \\\n",
    "                                        else enumerate(loader)):\n",
    "\n",
    "        # extract inputs and labels\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # apply cutmix augmentation\n",
    "        if CFG['cutmix'][0] > 0:\n",
    "            mix_decision = np.random.rand(1)\n",
    "            if mix_decision < CFG['cutmix'][0]:\n",
    "                inputs, labels = cutmix_fn(data   = inputs, \n",
    "                                           target = labels, \n",
    "                                           alpha  = cutmix[1])\n",
    "        else:\n",
    "            mix_decision = 0\n",
    "\n",
    "        # update scheduler on batch\n",
    "        if CFG['update_on_batch']:\n",
    "            scheduler.step(epoch + 1 + batch_idx / len(loader))\n",
    "\n",
    "        # passes and weight updates\n",
    "        with torch.set_grad_enabled(True):\n",
    "            \n",
    "            # forward pass \n",
    "            with amp_autocast():\n",
    "                preds = model(inputs)\n",
    "                if (CFG['cutmix'][0] > 0) and (mix_decision < CFG['cutmix'][0]):\n",
    "                    loss = criterion(preds, labels[0]) * labels[2] + criterion(preds, labels[1]) * (1. - labels[2])\n",
    "                else:\n",
    "                    loss = criterion(preds, labels)\n",
    "                    \n",
    "            # backward pass\n",
    "            if CFG['use_amp']:\n",
    "                scaler.scale(loss).backward()   \n",
    "            else:\n",
    "                loss.backward() \n",
    "\n",
    "            # update weights\n",
    "            if ((batch_idx + 1) % CFG['accum_iter'] == 0) or ((batch_idx + 1) == len(loader)):\n",
    "                if CFG['device'] == 'TPU':\n",
    "                    xm.optimizer_step(optimizer, barrier = True)\n",
    "                else:\n",
    "                    if CFG['use_amp']:\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "                    else:\n",
    "                        optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        # update loss\n",
    "        trn_loss.update(loss.item(), inputs.size(0))\n",
    "\n",
    "        # clear memory\n",
    "        del inputs, labels, preds, loss\n",
    "        gc.collect()\n",
    "\n",
    "    # output\n",
    "    return trn_loss.sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_dANCydQCEs0"
   },
   "outputs": [],
   "source": [
    "####### INFERENCE\n",
    "\n",
    "def valid_epoch(loader, model, criterion, CFG, device):\n",
    "\n",
    "    # switch regime\n",
    "    model.eval()\n",
    "\n",
    "    # running loss\n",
    "    val_loss = AverageMeter()\n",
    "\n",
    "    # preds placeholders\n",
    "    PROBS = []\n",
    "       \n",
    "    # loop through batches\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, labels) in (tqdm(enumerate(loader), total = len(loader)) if CFG['device'] != 'TPU' \\\n",
    "                                            else enumerate(loader)):\n",
    "\n",
    "            # extract inputs and labels\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # preds placeholders\n",
    "            logits = torch.zeros((inputs.shape[0], CFG['num_classes']), device = device)\n",
    "            probs  = torch.zeros((inputs.shape[0], CFG['num_classes']), device = device)\n",
    "\n",
    "            # compute predictions\n",
    "            for tta_idx in range(CFG['num_tta']): \n",
    "                preds   = model(get_tta_flips(inputs, tta_idx))\n",
    "                logits += preds / CFG['num_tta']\n",
    "                probs  += preds.softmax(axis = 1) / CFG['num_tta']\n",
    "\n",
    "            # compute loss\n",
    "            loss = criterion(logits, labels)\n",
    "            val_loss.update(loss.item(), inputs.size(0))\n",
    "\n",
    "            # store predictions\n",
    "            PROBS.append(probs.detach().cpu())\n",
    "\n",
    "            # clear memory\n",
    "            del inputs, labels, preds, loss\n",
    "            gc.collect()\n",
    "\n",
    "    # transform predictions\n",
    "    PROBS = torch.cat(PROBS).numpy()\n",
    "\n",
    "    # output\n",
    "    return val_loss.sum, PROBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V4hMCfrESTeN"
   },
   "outputs": [],
   "source": [
    "####### WRAPPER FUNCTION\n",
    "\n",
    "def run_fold(fold, trn_loader, val_loader, df_trn, df_val, CFG, device):\n",
    "\n",
    "    ##### PREPARATIONS\n",
    "    \n",
    "    # reset seed\n",
    "    seed_everything(CFG['seed'] + fold, CFG)\n",
    "\n",
    "    # get model\n",
    "    model, optimizer, scheduler = get_model(CFG, device)\n",
    "        \n",
    "    # placeholders\n",
    "    trn_losses  = []\n",
    "    val_losses  = []\n",
    "    val_metrics = []\n",
    "    lrs         = []\n",
    "\n",
    "    \n",
    "    ##### TRAINING AND INFERENCE\n",
    "\n",
    "    for epoch in range(CFG['num_epochs'] + CFG['fine_tune']):\n",
    "                \n",
    "        ### PREPARATIONS\n",
    "\n",
    "        # timer\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        # update data loaders if needed\n",
    "        if (CFG['step_size']) or (CFG['step_class']) or (CFG['step_p_aug']):\n",
    "            trn_loader, val_loader, _, _ = get_data(df, fold, CFG, epoch)   \n",
    "\n",
    "        # freeze layers if needed\n",
    "        if (CFG['fine_tune']) and (epoch == CFG['num_epochs']):\n",
    "            model, optimizer, scheduler = get_model(CFG, device, epoch)\n",
    "            model.load_state_dict(torch.load(CFG['out_path'] + 'weights_fold{}.pth'.format(fold),\n",
    "                                             map_location = device))\n",
    "            \n",
    "        # get losses\n",
    "        if epoch < CFG['num_epochs']:\n",
    "            trn_criterion, val_criterion = get_losses(CFG, device, epoch)\n",
    "\n",
    "\n",
    "        ### MODELING\n",
    "\n",
    "        # training\n",
    "        gc.collect()\n",
    "        if CFG['training']:\n",
    "            if CFG['device'] == 'TPU':\n",
    "                pl_loader = pl.ParallelLoader(trn_loader, [device])\n",
    "            trn_loss = train_epoch(loader     = trn_loader if CFG['device'] != 'TPU' else pl_loader.per_device_loader(device), \n",
    "                                   model      = model, \n",
    "                                   optimizer  = optimizer, \n",
    "                                   scheduler  = scheduler,\n",
    "                                   criterion  = trn_criterion, \n",
    "                                   epoch      = epoch,\n",
    "                                   CFG        = CFG,\n",
    "                                   device     = device)\n",
    "        else:\n",
    "            model.load_state_dict(torch.load(CFG['out_path'] + 'weights_fold{}.pth'.format(fold),\n",
    "                                             map_location = device))\n",
    "            trn_loss = np.nan\n",
    "\n",
    "        # inference\n",
    "        gc.collect()\n",
    "        if CFG['device'] == 'TPU':\n",
    "            pl_loader = pl.ParallelLoader(val_loader, [device])\n",
    "        val_loss, val_preds = valid_epoch(loader    = val_loader if CFG['device'] != 'TPU' else pl_loader.per_device_loader(device), \n",
    "                                          model     = model, \n",
    "                                          criterion = val_criterion, \n",
    "                                          CFG       = CFG,\n",
    "                                          device    = device)\n",
    "        \n",
    "\n",
    "        ### EVALUATION\n",
    "        \n",
    "        # reduce losses\n",
    "        if CFG['device'] == 'TPU':\n",
    "            trn_loss = xm.mesh_reduce('loss', trn_loss, lambda x: sum(x) / (len(df_trn) * xm.xrt_world_size()))\n",
    "            val_loss = xm.mesh_reduce('loss', val_loss, lambda x: sum(x) / (len(df_val) * xm.xrt_world_size()))\n",
    "            lr       = scheduler.state_dict()['_last_lr'][0] / xm.xrt_world_size()\n",
    "        else:\n",
    "            trn_loss = trn_loss / len(df_trn)\n",
    "            val_loss = val_loss / len(df_val)\n",
    "            lr       = scheduler.state_dict()['_last_lr'][0]\n",
    "            \n",
    "        # save LR and losses\n",
    "        lrs.append(lr)\n",
    "        trn_losses.append(trn_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        val_metrics.append((np.argmax(val_preds, axis = 1) == df_val['label']).sum() / len(df_val))\n",
    "        \n",
    "        # feedback\n",
    "        smart_print('- epoch {}/{} | lr = {:.6f} | trn_loss = {:.4f} | val_loss = {:.4f} | val_acc = {:.4f} | {:.2f} min'.format(\n",
    "            epoch + 1, CFG['num_epochs'] + CFG['fine_tune'], lrs[epoch],\n",
    "            trn_losses[epoch], val_losses[epoch], val_metrics[epoch],\n",
    "            (time.time() - epoch_start) / 60), CFG)\n",
    "        \n",
    "        # send to neptune\n",
    "        if CFG['tracking']:\n",
    "            neptune.send_metric('val_loss{}'.format(fold), val_losses[epoch])\n",
    "            neptune.send_metric('val_acc{}'.format(fold),  val_metrics[epoch])\n",
    "        \n",
    "        # export weights and save preds\n",
    "        if val_metrics[epoch] >= max(val_metrics):\n",
    "            smart_save(model.state_dict(), CFG['out_path'] + 'weights_fold{}.pth'.format(fold), CFG)\n",
    "            val_preds_best = val_preds.copy()\n",
    "        if CFG['save_all']:\n",
    "            smart_save(model.state_dict(), CFG['out_path'] + 'weights_fold{}_epoch{}.pth'.format(fold, epoch), CFG)      \n",
    "            \n",
    "    \n",
    "    return trn_losses, val_losses, val_metrics, val_preds_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0xCcLgESIYS3"
   },
   "outputs": [],
   "source": [
    "####### PLOTTING FUNCTION\n",
    "\n",
    "def plot_results(trn_losses, val_losses, val_metrics, fold, CFG):\n",
    "\n",
    "    # plot loss lines\n",
    "    plt.figure(figsize = (20, 8))\n",
    "    plt.plot(range(1, CFG['num_epochs'] + CFG['fine_tune'] + 1), trn_losses, color = 'red',   label = 'Train Loss')\n",
    "    plt.plot(range(1, CFG['num_epochs'] + CFG['fine_tune'] + 1), val_losses, color = 'green', label = 'Valid Loss') \n",
    "\n",
    "    # plot points with the best losses\n",
    "    x = np.argmin(np.array(val_losses)) + 1; y = min(val_losses)\n",
    "    xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n",
    "    plt.scatter(x, y, s = 200, color = 'green')\n",
    "    plt.text(x - 0.04*xdist, y - 0.045*ydist, 'loss = {:.4f}'.format(y), size = 15)\n",
    "\n",
    "    # annotations\n",
    "    plt.ylabel('Loss', size = 14); plt.xlabel('Epoch', size = 14)\n",
    "    plt.legend(loc = 2, fontsize = 'large')\n",
    "\n",
    "    # plot metric line\n",
    "    plt2 = plt.gca().twinx()\n",
    "    plt2.plot(range(1, CFG['num_epochs'] + CFG['fine_tune'] + 1), val_metrics, color = 'blue', label = 'Valid Accuracy')\n",
    "\n",
    "    # plot points with the best metric\n",
    "    x = np.argmax(np.array(val_metrics)) + 1; y = max(val_metrics)\n",
    "    xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n",
    "    plt.scatter(x, y, s = 200, color = 'blue')\n",
    "    plt.text(x - 0.05*xdist, y - 0.045*ydist, 'acc = {:.4f}'.format(y), size = 15)\n",
    "\n",
    "    # annotations\n",
    "    plt.ylabel('Accuracy', size = 14)\n",
    "    plt.title('Fold {}: Performance Dynamics'.format(fold), size = 18)\n",
    "    plt.legend(loc = 3, fontsize = 'large')\n",
    "\n",
    "    # export\n",
    "    plt.savefig(CFG['out_path'] + 'fig_perf_fold{}.png'.format(fold))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NtAEmeT80VjI"
   },
   "source": [
    "# CROSS-VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "id": "VIOZZY6cfxBx",
    "outputId": "c650471a-505c-476c-f671-046a56f39d2a"
   },
   "outputs": [],
   "source": [
    "####### CROSS-VALIDATION LOOP\n",
    "\n",
    "##### INITIALIZATION\n",
    "\n",
    "# timer\n",
    "cv_start = time.time()\n",
    "\n",
    "# clear memory\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "# placeholders\n",
    "oof = None\n",
    "perf = pd.DataFrame(columns = ['fold', 'epoch', 'trn_loss', 'val_loss', 'val_acc'])\n",
    "if not CFG['training']:\n",
    "    perf = pd.read_csv(CFG['out_path'] + 'tab_performance.csv')\n",
    "\n",
    "# amp settings\n",
    "amp_autocast = suppress\n",
    "if CFG['use_amp']:\n",
    "    amp_autocast = torch.cuda.amp.autocast\n",
    "    scaler       = torch.cuda.amp.GradScaler()       \n",
    "\n",
    "# adjust epochs if needed\n",
    "if not CFG['training']:\n",
    "    CFG['num_epochs'] = 1\n",
    "    CFG['fine_tune']   = False\n",
    "if CFG['debug']:\n",
    "    CFG['num_epochs'] = 2\n",
    "    CFG['num_folds']  = 2\n",
    "    CFG['fine_tune']   = 1\n",
    "    \n",
    "    \n",
    "##### CROSS-VALIDAION\n",
    "\n",
    "for fold in range(CFG['num_folds']):\n",
    "    \n",
    "    ### PERFORM MODELING\n",
    "    \n",
    "    # feedback\n",
    "    print('-' * 55)\n",
    "    print('FOLD {:d}/{:d}'.format(fold + 1, CFG['num_folds']))    \n",
    "    print('-' * 55) \n",
    "    \n",
    "    # prepare data\n",
    "    trn_loader, val_loader, df_trn, df_val = get_data(df, fold, CFG)   \n",
    "\n",
    "    # training and inference\n",
    "    if CFG['device'] != 'TPU':\n",
    "        trn_losses, val_losses, val_metrics, val_preds_best = run_fold(fold, trn_loader, val_loader, df_trn, df_val, CFG, device)\n",
    "    else:\n",
    "        def _mp_fn(rank, CFG):\n",
    "            torch.set_default_tensor_type('torch.FloatTensor')\n",
    "            device = xm.xla_device()\n",
    "            trn_losses, val_losses, val_metrics, val_preds_best = run_fold(fold, trn_loader, val_loader, df_trn, df_val, CFG, device)\n",
    "            if rank == 0:\n",
    "                np.save('trn_losses.npy',     np.array(trn_losses))\n",
    "                np.save('val_losses.npy',     np.array(val_losses))\n",
    "                np.save('val_metrics.npy',    np.array(val_metrics))\n",
    "                np.save('val_preds_best.npy', val_preds_best)\n",
    "        xmp.spawn(_mp_fn, args = (CFG, ), nprocs = CFG['num_workers'], start_method = 'fork')\n",
    "        trn_losses          = np.load('trn_losses.npy')\n",
    "        val_losses          = np.load('val_losses.npy')\n",
    "        val_metrics         = np.load('val_metrics.npy')\n",
    "        val_preds_best      = np.load('val_preds_best.npy')\n",
    "\n",
    "\n",
    "    ### SAVE RESULTS\n",
    "    \n",
    "    # performance table\n",
    "    if CFG['training']:\n",
    "        perf = pd.concat([perf, \n",
    "                          pd.DataFrame({'fold':     [fold] * (CFG['num_epochs'] + CFG['fine_tune']), \n",
    "                                        'epoch':    list(range(CFG['num_epochs'] + CFG['fine_tune'])),\n",
    "                                        'trn_loss': trn_losses,\n",
    "                                        'val_loss': val_losses,\n",
    "                                        'val_acc':  val_metrics})],\n",
    "                        axis = 0)\n",
    "        perf.to_csv(CFG['out_path'] + 'tab_performance.csv', index = False)\n",
    "            \n",
    "    # export OOF predictions\n",
    "    val_preds_df = pd.DataFrame(val_preds_best, columns = ['c' + str(class_idx) for class_idx in range(CFG['num_classes'])])\n",
    "    val_preds_df = pd.concat([df_val, val_preds_df], axis = 1)\n",
    "    oof = pd.concat([oof, val_preds_df], axis = 0).reset_index(drop = True)\n",
    "    oof.to_csv(CFG['out_path'] + 'oof.csv', index = False)\n",
    "\n",
    "\n",
    "    ### DISPLAY FEEDBACK\n",
    "\n",
    "    # feedback\n",
    "    print('-' * 55)\n",
    "    print('Best: acc = {:.4f} (epoch {}), loss = {:.4f} (epoch {})'.format(\n",
    "        np.max(val_metrics), np.argmax(val_metrics) + 1, np.min(val_losses), np.argmin(val_losses) + 1))\n",
    "    print('-' * 55)\n",
    "\n",
    "    # plot loss dynamics\n",
    "    if CFG['training']:\n",
    "        plot_results(trn_losses, val_losses, val_metrics, fold, CFG)\n",
    "\n",
    "\n",
    "##### FEEDBACK\n",
    "\n",
    "print('')\n",
    "print('Finished in {:.2f} minutes'.format((time.time() - cv_start) / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5bUh1-_0VjL"
   },
   "source": [
    "# EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cJQFNQsc0VjL",
    "outputId": "c21e5e9f-1f0d-408a-aa18-ceb4e37c96dc"
   },
   "outputs": [],
   "source": [
    "####### CHECK OOF PERFORMANCE\n",
    "\n",
    "# compute accuracy\n",
    "oof['pred'] = np.argmax(oof[['c' + str(class_idx) for class_idx in range(CFG['num_classes'])]].values, axis = 1)\n",
    "oof_acc     = (oof['pred'] == oof['label']).sum() / len(oof)\n",
    "oof_loss    = perf.groupby('fold')['val_loss'].agg('min').mean()\n",
    "\n",
    "# print results\n",
    "print('- OOF acc  = {:.4f}'.format(oof_acc))\n",
    "print('- OOF loss = {:.4f}'.format(oof_loss))\n",
    "\n",
    "# save results\n",
    "res = pd.DataFrame({'fold':     ['oof',], \n",
    "                    'epoch':    ['best'],\n",
    "                    'trn_loss': [np.nan],\n",
    "                    'val_loss': [oof_loss],\n",
    "                    'val_acc':  [oof_acc]})\n",
    "perf = pd.concat([perf, res], axis = 0)\n",
    "perf.to_csv(CFG['out_path'] + 'tab_performance.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "MWtfNOfkxNZr",
    "outputId": "78c86e7f-bbf6-482e-dc7f-940cbd65e2c8"
   },
   "outputs": [],
   "source": [
    "####### CONFUSION MATRIX\n",
    "\n",
    "# construct confusion matrx\n",
    "cm    = confusion_matrix(y_true = oof['label'], y_pred = oof['pred'], normalize = 'all')\n",
    "annot = np.around(cm, 2)\n",
    "\n",
    "# plot matrix\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "sns.heatmap(cm, cmap = 'Blues', annot = annot, lw = 0.5)\n",
    "ax.set_xlabel('Prediction')\n",
    "ax.set_ylabel('Ground Truth')\n",
    "ax.set_aspect('equal')\n",
    "    \n",
    "# export plot\n",
    "plt.savefig(CFG['out_path'] + 'fig_confusion.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7YUt-UUkTlw"
   },
   "source": [
    "####### PREDICTIONS WITH GRADCAM SETTINGS\n",
    "\n",
    "# images per classs\n",
    "sample = 4\n",
    "\n",
    "# get augmentations\n",
    "_, sample_augs = get_augs(CFG, image_size = CFG['image_size'])\n",
    "\n",
    "# get model with weights\n",
    "model, _, _ = get_model(CFG, device)\n",
    "model.load_state_dict(torch.load(CFG['out_path'] + 'weights_fold{}.pth'.format(fold), map_location = device))\n",
    "\n",
    "# feature and target modules\n",
    "if 'efficient' in CFG['backbone']:\n",
    "    feature_block = model.blocks\n",
    "    target_layers = ['6']\n",
    "elif 'vit_base_patch16_224' in CFG['backbone']:\n",
    "    #feature_block = model.blocks\n",
    "    target_layers = model.blocks[11].mlp #model.head\n",
    "else:\n",
    "    feature_block = model.layer4\n",
    "    target_layers = ['2']\n",
    "\n",
    "# gradcam\n",
    "grad_cam = GradCam(model              = model, \n",
    "                   feature_module     = feature_block,\n",
    "                   target_layer_names = target_layers, \n",
    "                   use_cuda           = True)\n",
    "\n",
    "# prepare dataframes\n",
    "oof['correct']    = oof['pred'] == oof['label']\n",
    "oof['confidence'] = np.max(oof[['c' + str(class_idx) for class_idx in range(CFG['num_classes'])]].values, axis = 1)\n",
    "oof               = oof.sort_values(['label', 'confidence'], ascending = True)\n",
    "rights = oof.loc[oof['correct'] == True].groupby('label').tail(sample).reset_index(drop  = True)\n",
    "wrongs = oof.loc[oof['correct'] == False].groupby('label').tail(sample).reset_index(drop = True)\n",
    "\n",
    "# datasets\n",
    "right_dataset = LeafData(data      = rights, \n",
    "                         directory = CFG['data_path'] + 'train_images/',\n",
    "                         transform = sample_augs,\n",
    "                         labeled   = True)\n",
    "wrong_dataset = LeafData(data      = wrongs,  \n",
    "                         directory = CFG['data_path'] + 'train_images/',\n",
    "                         transform = sample_augs,\n",
    "                         labeled   = True)\n",
    "# data loaders\n",
    "right_loader = DataLoader(dataset     = right_dataset, \n",
    "                          batch_size  = sample * CFG['num_classes'], \n",
    "                          shuffle       = False, \n",
    "                          num_workers = 0,\n",
    "                          pin_memory  = True)\n",
    "wrong_loader = DataLoader(dataset     = wrong_dataset, \n",
    "                          batch_size  = sample * CFG['num_classes'],\n",
    "                          shuffle       = False, \n",
    "                          num_workers = 0,\n",
    "                          pin_memory  = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XukFeOwynacH",
    "outputId": "b600ac57-5707-4b1b-a8e6-27ccc442b860"
   },
   "source": [
    "####### EXAMINE WRONG PREDICTIONS \n",
    "\n",
    "# display and save image grid\n",
    "fig = plt.figure(figsize = (20, 20))\n",
    "for batch_idx, (inputs, labels) in enumerate(wrong_loader):\n",
    "    for i in range(inputs.shape[0]):\n",
    "\n",
    "        # compute gradcam\n",
    "        grayscale_cam = grad_cam(inputs[i].unsqueeze(0), None)\n",
    "        cam = show_cam_on_image(inputs[i].numpy().transpose(1, 2, 0), grayscale_cam)\n",
    "\n",
    "        # plot results\n",
    "        ax = fig.add_subplot(CFG['num_classes'], sample, i + 1, xticks = [], yticks = [])     \n",
    "        plt.imshow(cam)\n",
    "        ax.set_title('{} [pred = {}, p = {:.2f}]'.format(\n",
    "            labels[i].numpy(), wrongs.iloc[i]['pred'], wrongs.iloc[i]['confidence']), color = 'red')\n",
    "        \n",
    "# export\n",
    "plt.savefig(CFG['out_path'] + 'fig_preds_wrong.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 913
    },
    "id": "FPeCZnOlr8qc",
    "outputId": "e6b94978-7c4b-45aa-99ce-204333200d06"
   },
   "source": [
    "####### EXAMINE RIGHT PREDICTIONS \n",
    "\n",
    "# display and save image grid\n",
    "fig = plt.figure(figsize = (20, 20))\n",
    "for batch_idx, (inputs, labels) in enumerate(right_loader):\n",
    "    for i in range(inputs.shape[0]):\n",
    "\n",
    "        # compute gradcam\n",
    "        grayscale_cam = grad_cam(inputs[i].unsqueeze(0), None)\n",
    "        cam = show_cam_on_image(inputs[i].numpy().transpose(1, 2, 0), grayscale_cam)\n",
    "\n",
    "        # plot results\n",
    "        ax = fig.add_subplot(CFG['num_classes'], sample, i + 1, xticks = [], yticks = [])     \n",
    "        plt.imshow(cam)\n",
    "        ax.set_title('{} [pred = {}, p = {:.2f}]'.format(\n",
    "            labels[i].numpy(), wrongs.iloc[i]['pred'], wrongs.iloc[i]['confidence']), color = 'green')\n",
    "        \n",
    "# export\n",
    "plt.savefig(CFG['out_path'] + 'fig_preds_right.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2g1eeDFgleGB"
   },
   "outputs": [],
   "source": [
    "####### EXPORT CONFIGURATION\n",
    "\n",
    "# store performance values\n",
    "CFG['time_min'] = (time.time() - cv_start) / 60\n",
    "CFG['oof_acc']  = oof_acc\n",
    "CFG['oof_loss'] = oof_loss\n",
    "\n",
    "# save DF\n",
    "params = pd.DataFrame.from_dict(CFG, orient = 'index', columns = ['value'])\n",
    "params.to_csv(CFG['out_path'] + 'tab_configuration.csv', index = True)\n",
    "\n",
    "# save dictionary\n",
    "pickle.dump(CFG, open(CFG['out_path'] + 'configuration.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocE5d2wpCCk2"
   },
   "outputs": [],
   "source": [
    "####### SENDING TO NEPTUNE\n",
    "\n",
    "if CFG['tracking']:\n",
    "\n",
    "    # metrics\n",
    "    neptune.send_metric('oof_acc',  oof_acc)\n",
    "    neptune.send_metric('oof_loss', oof_loss)\n",
    "        \n",
    "    # images\n",
    "    neptune.send_image('confusion',   CFG['out_path'] + 'fig_confusion.png')\n",
    "    #neptune.send_image('predictions', CFG['out_path'] + 'fig_preds_right.png')\n",
    "    #neptune.send_image('predictions', CFG['out_path'] + 'fig_preds_wrong.png')\n",
    "\n",
    "    # model weights\n",
    "    for fold in range(CFG['num_folds']):\n",
    "        neptune.send_artifact(CFG['out_path'] + 'weights_fold{}.pth'.format(fold))\n",
    "\n",
    "    # OOF predictions\n",
    "    neptune.send_artifact(CFG['out_path'] + 'oof.csv')\n",
    "\n",
    "    # CFG and performance\n",
    "    neptune.send_artifact(CFG['out_path'] + 'tab_performance.csv') \n",
    "    neptune.send_artifact(CFG['out_path'] + 'tab_configuration.csv') \n",
    "\n",
    "    # stop experiment\n",
    "    neptune.stop()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "-9ZKt08y0ViT",
    "T2OuAGJw0Viv",
    "EVog-f8UjJzC",
    "SVfS9wOWAouA",
    "NtAEmeT80VjI"
   ],
   "name": "pytorch-training-v118.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
