{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-million",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### CONFIGURATION\n",
    "\n",
    "class CFG:\n",
    "\n",
    "    # environment\n",
    "    environment = 'local'  # work environment ('kaggle', 'colab', 'local')\n",
    "    device      = 'CPU' # device ('CPU', 'GPU', 'TPU')\n",
    "    num_workers = 4        # no. cores\n",
    "\n",
    "    # general\n",
    "    version  = 128   # notebook version (for saving outputs)\n",
    "    debug    = False # debug mode runs 5 batches for 2 epochs \n",
    "    training = False # if False, only inference is run\n",
    "    tracking = False # track results using neptune.ai\n",
    "    seed     = 13353 # random state\n",
    "\n",
    "    # data\n",
    "    num_folds  = 5      # number of CV folds\n",
    "    data_2019  = True   # append 2019 labeled data to training folds (1a)\n",
    "    data_pl    = 0.2    # False or percentage of appended pseudo-labeled data (1b)\n",
    "    data_ext   = False  # False or list with external dataset ids (2, 3, 4, 5)\n",
    "    drop_dupl  = True   # drop duplicate images from training folds\n",
    "    drop_outs  = False  # drop outliers from training folds\n",
    "    oversample = False  # enable oversampling through WeightedRandomSampler()\n",
    "    \n",
    "    # label noise\n",
    "    drop_noise = False  # False or percentage of removed noisy labels in training folds\n",
    "    flip_noise  = False  # False or percentage of flipped noisy labels in training folds\n",
    "\n",
    "    # image size and augmentations \n",
    "    image_size   = 512                # image size after random crop\n",
    "    crop_scale   = (0.10, 1)          # min scale, max scale\n",
    "    gr_shuffle     = (3, 3)             # number of tiles in shuffled grid\n",
    "    ssr          = [0.05, 0.05, 360]  # shift, scale, rotation limits\n",
    "    huesat       = [20, 20, 20]       # hue, saturation, value limits\n",
    "    bricon       = [0.1, 0.1]         # brightness, contrast limits\n",
    "    blur_limit   = 3                  # blur limit\n",
    "    dist_limit   = 0.1                # distortion limit\n",
    "    cutout       = [5, 0.1]           # number of squares, size of squares\n",
    "    p_augment    = 0.5                # prob. of augmentations except for flips\n",
    "    cutmix       = [0, 1]             # cutmix batch-level probability, alpha\n",
    "    normalize    = False              # pixel normalization (False, 'dataset', 'imagenet')\n",
    "    pairing      = False              # overlay of a random image from the same class\n",
    "    pairing_prob = 0.6                # probability of an image to get another image added\n",
    "    pixel_crop   = 150                # hight and width of the crop\n",
    "\n",
    "    # model architecture\n",
    "    backbone = 'tf_efficientnet_b4_ns'  # convolutional backbone\n",
    "    weights  = 'imagenet'              # weights ('empty', 'imagenet', 'custom')\n",
    "    save_all = False                   # save weights from each epoch\n",
    "\n",
    "    # pretrained model\n",
    "    pr_version     = 3   # notebook version (2, 3, 4, 5)\n",
    "    pr_num_classes = 10  # no. classes (2: 4, 3: 10, 4: 2, 5: 17)\n",
    "\n",
    "    # training\n",
    "    batch_size  = 32    # no. images per batch\n",
    "    num_epochs  = 10    # no. epochs per fold\n",
    "    fine_tune    = 2     # fine-tuning dense layers (False or no. epochs)\n",
    "    accum_iter  = 1     # no. batches for gradient accumalation\n",
    "    use_amp     = True  # automated mixed precision mode\n",
    "\n",
    "    # learning rate and optimizer\n",
    "    eta     = 1e-4    # starting learning rate\n",
    "    eta_min = 1e-6    # ending learning rate\n",
    "    optim   = 'AdamP' # LR optimizer ('Adam', 'AdamW', 'AdamP')\n",
    "    decay   = 0       # weight decay of optimizer (L2 regularization)\n",
    "\n",
    "    # learning rate scheduler\n",
    "    warmup          = 1                  # no. epochs for warmup\n",
    "    schedule        = 'CosineAnnealing'  # LR scheduler after warmup\n",
    "    update_on_batch = True               # update LR after every batch or epoch\n",
    "\n",
    "    # loss function\n",
    "    loss_fn     = 'OHEM'       # loss function ('CE', 'OHEM', 'SCE', 'CCE', 'Focal', 'FocalCosine', 'Taylor', 'BiTempered')\n",
    "    smoothing   = 0.2          # label smoothing (works with all losses)\n",
    "    ohem        = 0.8          # OHEM loss parameters: top-k percentage\n",
    "    sce         = [0.1, 1.0]   # SCE loss parameters: alpha, beta\n",
    "    cce         = 5            # CCE loss parameters: gamma\n",
    "    focal       = [1, 2]       # Focal loss parameters: alpha, gamma\n",
    "    focalcosine = [1, 2, 0.1]  # FocalCosine loss parameters: alpha, gamma, xent\n",
    "    taylor      = 2            # Taylor loss parameters: n\n",
    "    bitempered  = [0.3, 1.0]   # BiTempered loss parameters: t1, t2\n",
    "\n",
    "    # epoch-based changes\n",
    "    step_size  = False  # False or list with image_size multiplier for each epoch\n",
    "    step_class = False  # False or list with num_classes for each epoch (2 or 5)\n",
    "    step_p_aug = False  # False or list with p_augment multiplier for each epoch\n",
    "    step_loss  = False  # False or list with loss functions for each epoch\n",
    "\n",
    "    # inference\n",
    "    num_tta = 1  # no. TTA flips (between 1 and 8)\n",
    "    \n",
    "    data_path = '../../data/'\n",
    "    \n",
    "    \n",
    "CFG = dict(vars(CFG))\n",
    "for key in ['__dict__', '__doc__', '__module__', '__weakref__']:\n",
    "    del CFG[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler, WeightedRandomSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "from torch.autograd import Function\n",
    "\n",
    "os.system('pip install timm')\n",
    "import timm\n",
    "from timm.utils import *\n",
    "\n",
    "from contextlib import suppress\n",
    "\n",
    "os.system('pip install --upgrade -U albumentations')\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "os.system(\"pip install git+'https://github.com/ildoonet/pytorch-gradual-warmup-lr.git'\")\n",
    "from warmup_scheduler import GradualWarmupScheduler  \n",
    "\n",
    "os.system('pip install adamp')\n",
    "from adamp import AdamP\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import cv2\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from scipy.special import softmax\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "####### UTILITIES\n",
    "\n",
    "##### RANDOM FOR LOOPS\n",
    "\n",
    "def randomly(seq):\n",
    "    shuffled = list(seq)\n",
    "    random.shuffle(shuffled)\n",
    "    return iter(shuffled)\n",
    "\n",
    "\n",
    "##### DEVICE-AWARE PRINTING \n",
    "\n",
    "def smart_print(expression, CFG):\n",
    "    if CFG['device'] != 'TPU':\n",
    "        print(expression)\n",
    "    else:\n",
    "        xm.master_print(expression)\n",
    "\n",
    "\n",
    "##### DEVICE-AWARE SAVING\n",
    "\n",
    "def smart_save(weights, path, CFG):\n",
    "    if CFG['device'] != 'TPU':\n",
    "        torch.save(weights, path)    \n",
    "    else:\n",
    "        xm.save(weights, path) \n",
    "\n",
    "    \n",
    "##### RANDOMNESS\n",
    "\n",
    "def seed_everything(seed, CFG):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    smart_print('Setting random seed to {}...'.format(seed), CFG)\n",
    "    \n",
    "seed_everything(CFG['seed'], CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### 2020 COMPETITION DATA\n",
    "\n",
    "# import data\n",
    "df = pd.read_csv(CFG['data_path'] + 'train_with_imagenet_label.csv')\n",
    "df = df.loc[df['source'] == 2020].reset_index(drop = True)\n",
    "    \n",
    "# num classes\n",
    "CFG['num_classes'] = df['label'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-visibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### DATASET\n",
    "\n",
    "class LeafData(Dataset):\n",
    "    \n",
    "    # initialization\n",
    "    def __init__(self, \n",
    "                 data, \n",
    "                 directory, \n",
    "                 transform    = None, \n",
    "                 labeled      = False,\n",
    "                 pairing      = False,\n",
    "                 pairing_prob = 0.01,\n",
    "                 pixel_crop   = 50,\n",
    "                 seed         = 0):\n",
    "        \n",
    "        self.data         = data\n",
    "        self.directory    = directory\n",
    "        self.transform    = transform\n",
    "        self.labeled      = labeled\n",
    "        self.pairing      = pairing\n",
    "        self.pairing_prob = pairing_prob\n",
    "        self.seed         = seed\n",
    "        self.counter      = 0\n",
    "        self.pixel_crop   = pixel_crop\n",
    "        if pairing:\n",
    "            self.sampled_idx = self.data.sample(frac=self.pairing_prob, random_state=self.seed).index\n",
    "        \n",
    "    # length\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    # get item  \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # import\n",
    "        path  = os.path.join(self.directory, self.data.iloc[idx]['image_id'])\n",
    "        image = cv2.imread(path)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "        # augmentations\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image = image)['image']\n",
    "            \n",
    "        if self.pairing:\n",
    "            if idx in self.sampled_idx:\n",
    "                \n",
    "                try:\n",
    "                    add_path     = os.path.join(self.directory, self.data.loc[self.data.label==self.data.iloc[idx]['label']].sample(1, random_state=self.seed)['image_id'].iloc[0])\n",
    "                except:\n",
    "                    print(self.data.sample(1, random_state=self.seed))\n",
    "                    add_path     = os.path.join(self.directory, self.data.sample(1, random_state=self.seed)['image_id'].iloc[0])\n",
    "                    self.counter += 1\n",
    "                    \n",
    "                add_image = cv2.imread(add_path)\n",
    "                add_image = cv2.cvtColor(add_image, cv2.COLOR_BGR2RGB)\n",
    "                if self.transform is not None:\n",
    "                    add_image = self.transform(image = add_image)['image']\n",
    "                    \n",
    "                max_x = add_image.shape[2] - self.pixel_crop\n",
    "                max_y = add_image.shape[1] - self.pixel_crop\n",
    "                \n",
    "                x = torch.randint(0, max_x, (1,))\n",
    "                y = torch.randint(0, max_y, (1,))\n",
    "                crop  = add_image[:, y: y + self.pixel_crop, x: x + self.pixel_crop]\n",
    "                image[:, y: y + self.pixel_crop, x: x + self.pixel_crop] = crop\n",
    "                \n",
    "        \n",
    "        # output\n",
    "        if self.labeled:\n",
    "            labels = torch.tensor(self.data.iloc[idx]['label']).long()\n",
    "            return image, labels\n",
    "        else:\n",
    "            return image\n",
    "        \n",
    "        def get_counter(self):\n",
    "            print(f'{self.counter} observations were cropped with the sample from another class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### AUGMENTATIONS\n",
    "\n",
    "def get_augs(CFG, image_size = None, p_augment = None):\n",
    "\n",
    "    # update epoch-based parameters\n",
    "    if image_size is None:\n",
    "        image_size = CFG['image_size']\n",
    "    if p_augment is None:\n",
    "        p_augment = CFG['p_augment']\n",
    "\n",
    "    # normalization\n",
    "    if CFG['normalize']:\n",
    "        if CFG['normalize'] == 'dataset':\n",
    "            CFG['pixel_mean'] = (0.442, 0.511, 0.318)\n",
    "            CFG['pixels_std'] = (0.233, 0.236, 0.225)\n",
    "        elif CFG['normalize'] == 'imagenet':\n",
    "            CFG['pixel_mean'] = (0.485, 0.456, 0.406)\n",
    "            CFG['pixels_std'] = (0.229, 0.224, 0.225)\n",
    "    else:\n",
    "        CFG['pixel_mean'] = (0, 0, 0)\n",
    "        CFG['pixels_std'] = (1, 1, 1)\n",
    "\n",
    "    # train augmentations\n",
    "    train_augs = A.Compose([A.RandomResizedCrop(height = image_size, \n",
    "                                                width  = image_size,\n",
    "                                                scale  = CFG['crop_scale']),\n",
    "                            A.RandomGridShuffle(p    = p_augment,\n",
    "                                              grid = CFG['gr_shuffle']),\n",
    "                            A.Transpose(p = 0.5),\n",
    "                            A.HorizontalFlip(p = 0.5),\n",
    "                            A.VerticalFlip(p = 0.5),\n",
    "                            A.ShiftScaleRotate(p            = p_augment,\n",
    "                                               shift_limit  = CFG['ssr'][0],\n",
    "                                               scale_limit  = CFG['ssr'][1],\n",
    "                                               rotate_limit = CFG['ssr'][2]),\n",
    "                            A.HueSaturationValue(p               = p_augment,\n",
    "                                                 hue_shift_limit = CFG['huesat'][0],\n",
    "                                                 sat_shift_limit = CFG['huesat'][1],\n",
    "                                                 val_shift_limit = CFG['huesat'][2]),\n",
    "                            A.RandomBrightnessContrast(p                = p_augment,\n",
    "                                                       brightness_limit = CFG['bricon'][0],\n",
    "                                                       contrast_limit   = CFG['bricon'][1]),\n",
    "                            A.OneOf([A.MotionBlur(blur_limit   = CFG['blur_limit']),\n",
    "                                     A.MedianBlur(blur_limit   = CFG['blur_limit']),\n",
    "                                     A.GaussianBlur(blur_limit = CFG['blur_limit'])], \n",
    "                                     p = p_augment),\n",
    "                            A.OneOf([A.OpticalDistortion(distort_limit = CFG['dist_limit']),\n",
    "                                     A.GridDistortion(distort_limit    = CFG['dist_limit'])], \n",
    "                                     p = p_augment),\n",
    "                            A.Cutout(p          = p_augment, \n",
    "                                     num_holes  = CFG['cutout'][0], \n",
    "                                     max_h_size = np.int(CFG['cutout'][1] * image_size), \n",
    "                                     max_w_size = np.int(CFG['cutout'][1] * image_size)),\n",
    "                            A.Normalize(mean = CFG['pixel_mean'],\n",
    "                                        std  = CFG['pixels_std']),\n",
    "                            ToTensorV2()\n",
    "                           ])\n",
    "\n",
    "    # test augmentations\n",
    "    test_augs = A.Compose([A.SmallestMaxSize(max_size = image_size),\n",
    "                           A.CenterCrop(height = image_size, \n",
    "                                        width  = image_size),\n",
    "                           A.Normalize(mean = CFG['pixel_mean'],\n",
    "                                       std  = CFG['pixels_std']),\n",
    "                           ToTensorV2()\n",
    "                           ])\n",
    "    \n",
    "    # output\n",
    "    return train_augs, test_augs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq = df.imagenet_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-rehabilitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, test_augs = get_augs(CFG, image_size = CFG['image_size'], p_augment = CFG['p_augment'])\n",
    "\n",
    "\n",
    "    \n",
    "for i,label in enumerate(list(df_freq.index)):\n",
    "    if os.path.exists(f'{CFG[\"data_path\"]}imagenet_classes/{label}.png'):\n",
    "        continue\n",
    "    else:\n",
    "        if df_freq[label]<5:\n",
    "            fig, axs = plt.subplots(1, df_freq[label], facecolor='w', edgecolor='k', figsize = (100, 40))\n",
    "        else:\n",
    "            fig, axs = plt.subplots(1,5, facecolor='w', edgecolor='k', figsize = (100, 40))\n",
    "        \n",
    "        if df_freq[label]!=1:\n",
    "            axs = axs.ravel()\n",
    "\n",
    "        train_dataset =  LeafData(data    = df.loc[df.imagenet_label==label,:].head(5), \n",
    "                             directory    = CFG['data_path'] + 'train_images/',\n",
    "                             transform    = test_augs,\n",
    "                             labeled      = True, \n",
    "                             seed         = CFG['seed'])\n",
    "\n",
    "        train_loader  = DataLoader(dataset    = train_dataset, \n",
    "                                  batch_size  = 5, \n",
    "                                  shuffle     = False, \n",
    "                                  num_workers = 0,\n",
    "                                  pin_memory  = True)\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            if df_freq[label]==1:\n",
    "                for img_id, image in enumerate(inputs):\n",
    "                    axs.imshow(image.permute(1, 2, 0))\n",
    "                    axs.set_title(label)\n",
    "            else:    \n",
    "                for img_id, image in enumerate(inputs):\n",
    "                    axs[img_id].imshow(image.permute(1, 2, 0))\n",
    "                    axs[img_id].set_title(label)\n",
    "\n",
    "        plt.savefig(f'{CFG[\"data_path\"]}imagenet_classes/{label}.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
